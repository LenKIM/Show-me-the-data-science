

## 이미지가 주어졌을 때, 각 픽셀이 어디에 속하는지 분류하는 것을 **Semantic Segmentation**



어떤 이미지가 들어왔을 때, 원핫벡터의 길이는 클래스를 길이.



어디에 사용되는가? 자율주행에 사용됨.

4개의 논문을 볼거임

- Fully Convolutional Networks for Semantic Seqmentataion
  - Atrouc Convolution 을 알아보기 위해. 논문을 볼 것
- Deconvolutaion network
  - 디커플링을 많이 함



# Fully Convolutional Networks for Semantic Seqmentataion

모든 네트워크가 Fully Conv로 이루어져 FC가 없는것.

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx56n70bljj313y0pigvo.jpg)

기존의 있는 네트워크를 Fully Conv로 만든다는 것은 무엇인지?



![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx56qd0e63j314b0pj14e.jpg)

10 * 10 * 100 이면 만개의 숫자가 들어 있을 것이다. 당연히, 한 줄로 flatten하면 1만 그런데, 이를 4096의 사이즈를 만들려고 한다면? 10000 * 4096을 conv해서 사이즈를 조절한다.

어떤 layer를 컨벌루를 한다는 것은 같은 필터를 가진 것을 컨벌루한다는 의미-

**즉, reshape를 하는 것이 아니라, conv를 통해서 FC한 것과 같은 유사한 사이즈를 만드는 것**

1*1 * 해당 Class를 만드는 것.

이렇게 하면 장점은 입력 이미지 사이즈가 클 경우, 파라미터가 크기 않다.

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fx56zfjq59j313b0om465.jpg)

2번째 그림은 3차원 백터

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fx570g6ug9j314e0pjdor.jpg)

이제 결과로부터 heatmap을 할 수 있다.

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx570s4eouj31480px7h2.jpg)

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx57189syuj314u0pxamo.jpg)

그림판에서 이미지를 사이즈를 키우는 것을 interpolotion이라고 하는데, 여기 논문에서는 Deconvolution이라고 한다.

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx573xg1r7j313t0owqba.jpg)

즉, Deconvolution이란, 컨벌의 반대 행위

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fx574h7drxj313t0ph14p.jpg)

필터에 스칼라 값을 곱한 뒤에 놓는다. 다음 바로 1칸(if stride is 2) 옆에 가서 또 스칼라를 곱한 뒤 놓는다.

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fx5771cpm3j313z0phwqu.jpg)

너무많은 conv을 하면 정보가 많이 날라가기 때문에, skip connection이라는 것을 사용한다.



## SEMANTIC IMAGE SEGMENTATION WITH DEEP CON-VOLUTIONAL NETS AND FULLU CONNECTED CRFs

논문은 문제 제기로 시작됨,

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fx57b2peuoj313y0pjadl.jpg)

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fx57bd99whj313z0pqh09.jpg)

1번째는 샘플링을 할 때 문제가 발생함.

2번째는 윤곽선을 정확하게 못따는 문제가 있어, Conditional random field라는 것을 할용함.



### Atrous convolution?

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx57fe6d8vj313t0pvard.jpg)

중간중간에 0을 넣어서 다리를 얼마나 더 벌릴지 만든다. 즉, 이전의 output보다 더 dense한 featare map을 만드는 것이 목표이다.

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx57hfchghj314y0pygut.jpg)

컨디션 랜덤필드는?

확률모델에서 RGB픽셀들이 들어 있는데, 각 픽셀마다 라벨이 들어있다.

빨간석으로 연결되어 있는 것은 바로 인접해있는 클래스는 비슷한 feature를 가질 것이라고 가정하는 것.



![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx57ih9yfej31460pm7gr.jpg)

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx57j8plufj31450plh3f.jpg)

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx57jwqq7hj31470q416e.jpg)

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx57kb9teqj314g0q3wy0.jpg)



## Learning Deconvolution Network for semantic Segmentation

 ![](https://ws3.sinaimg.cn/large/006tNbRwgy1fx57lu4rrpj30zz0on7ku.jpg)

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx57mjhlirj313x0po4iu.jpg)

이 영역은 리셉티브 필드 (receptive field)라고 불리는 초모수 (hyperparameter) 이다.

큰 물질과 작은 물질을 놓치는 경우가 많다. 그러므로

1 * 1 까지 줄여버린 다음에 복원시켜버리자.

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fx57p7ifohj31470pydxo.jpg)

이를 해결하기 위해서 unpooling을 실시한다.

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx57qf4s31j313w0pn18y.jpg)

**여기서 말하는 unpooling은 어려운 행위이다. switch variables를 갖고 동작을 취해야 한다.**

switch variables는 좌우 대칭하면서 값을 저장하고 활용한다.

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx57t79u7fj313u0pntj2.jpg)

앙상블 모델을 활용했다. **네트워크 자체가 여러개 있다.**

하나의 이미지를 통째로 넣는 것이 아니라, 여러 개의 모델을 넣는 것.

## DeepLab

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fx57wyiyfuj316x0nstne.jpg)

위 개념들을 활용하고 ASPP라는 것이 추가됨.

문제부터 나열하면 

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fx57xolvhwj313x0pnti5.jpg)

이러한 문제를

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx57ydp3vrj313w0pgnbi.jpg)

해결한 방법.

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fx57znaytyj314s0pr7jd.jpg)

Atrous Conv과 Deconv의 차이는??

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fx580vr8e7j314c0pygzz.jpg)

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx581l1oz2j313x0psale.jpg)

이미지를 줄여도 알아볼 수 있다.



## Full-Resolution Residual Networks for Semantic Segmentation

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fx589etxpmj310d0p7qd2.jpg)

## 그 외

1. U-Net  
   pix2pix와 같은 GAN에서 많이 사용함.  
   ![](https://ws3.sinaimg.cn/large/006tNbRwgy1fx58cl9rlij30nk0nh790.jpg)
2. Deep contextual networks  
   ![](https://ws4.sinaimg.cn/large/006tNbRwgy1fx58cyre5dj30sh0oadnf.jpg)
3. ![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx58dcegxmj30xb0mgn43.jpg)
4. ![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx58e4vp57j31100n1gu3.jpg)
5. 
6. 