## 4가지 CNN 살펴보기

1. **AlexNet**
2. **VGG**
3. **GoogLeNet**
4. **ResNet**



*레이어가 많이 쌓이면 성능이 좋아질 가능성이 있다.*

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fwc9bc25igj30yi0l1do1.jpg)

## AlexNet

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fwc9fd2866j31410o3qo5.jpg)

윗단과 아래닷을 2개로 나눈 이유는 하드웨어 문제 때문에.

파라미터의 수를 계산하는 것이 좋다.

딥러닝의 초석을 다룬 것으로 ReLU가 쓰인다.

분류에 있어서는 ReLU가 좋다.

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fwc9hc95h0j30x50mdq97.jpg)

#### **Faster Convergence**  빨리 수렴하게 만들어 준다.



![](https://ws1.sinaimg.cn/large/006tNbRwgy1fwc9ikcr2hj30wr0pgqfl.jpg)

다음의 일종의 정규화인데, 일정 부분만 높게 책정하는 것을 말합니다. (LRN)



**그럼 Regularization을 어떻게 했는가?**

AlexNet에는 2가지 정규화함수가 들어간다.

- Data augmentation
- Dropout

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fwc9jwymr5j30zq0mzk16.jpg)

**Data augmentation**

말그래도 데이터를 늘리는 것을 말한다.

Label Transformation

하나의 그림에서 다양한 데이터를 만들어 낼 수 있다.

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fwc9lu9m23j30y20oaaqr.jpg)![](https://ws4.sinaimg.cn/large/006tNbRwgy1fwc9mp7oapj312i0o244j.jpg)

좌우 반전과 smaller를 해서 데이터가 만장이라면 2000만장으로 뻥튀기 시킬 수 있다.

이 그림은 RGB니까 특정 값을 더해서, 얼마나 변했는지 학습을 통해서 뽑아내고 그걸 학습률로 넣는다.

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fwc9p4sclaj30xh0nn47e.jpg)

#### Dropout

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fwc9q2yno2j30x50oqdxk.jpg)

원래 드롭다운은 노드를 0으로 만드는 것이지만- AlexNet에서는 0.5를 노드에 곱한것.

## VGG network

아주 간단한 구조로 좋은 성능을 만들어 냈다.

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fwc9sd27zvj30uh0od47p.jpg)



## GoogLeNet

우편에 들어가는 글자인식에 사용된 알고리즘.

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fwc9taky0kj31390ougw6.jpg)

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fwc9u89ow9j30xs0ppagd.jpg)

아래부분이 진짜 사용된 것이다.

채널방향으로 더한 것 

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fwcaj7yfsgj315l0lzwkr.jpg)

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fwc9wiplp2j311j0mltg3.jpg)

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fwc9wuk23kj30z40nok2l.jpg)

 ![](https://ws2.sinaimg.cn/large/006tNbRwgy1fwc9z1s2sfj30uh0nzgpy.jpg)

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fwc9zf0byfj30ve0pfjwe.jpg)

![image-20181018135004682](/Users/len/Library/Application Support/typora-user-images/image-20181018135004682.png)

### 레이아웃을 하나 늘었을 뿐인데 컨벌루션(1x1)을 하나했을 뿐인데, 파라미터가 반이상 줄었다? 왜 그렇게 되었는가?



컨벌루션이란 동일한 필터가 돌아다니면서 찍는다. Input와 output 채널이 돌면서 찍는다. 

각각이 1X1으로 컨벌루션을 계속해서 파라미터를 계속 줄인다.

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fwca9wewh0j314p0mnk0s.jpg)



그럼 GoogLeNet으로 배울 수 있는 것은? 

채널을 줄었다라는 개념이다. Inception module이 가질 수 있는 이익은? 

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fwcaaznl5ij30rp0chte0.jpg)

 **갈림길을 만듬으로써 장점은?**

입력이미지에 미치는, 취합되는 정보의 영역이 매우 다양하게 결과물이 나올 수 있게 만들었다.

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fwcadqm9jwj31010oeqnr.jpg)

### Inception v4 

파라미터를 줄이기 위해 얼마나 노력했는지 알 수 있다.

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fx8jpfl3eaj311n0qhk1k.jpg)

파라미터를 줄이기 위해 7x1 / 1X7을 활용한다.

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fx8jpqdpslj31130p246y.jpg)

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx8jq7om6gj310s0p7k0g.jpg)





이렇게 만드니까 잘 되더라-

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fwcaob5u7ij30z70oz470.jpg)



# ResNet

동일한 네트워크가 여러 곳에서 범용적으로 사용되었다는 것은 좋은것이다.

**보틀렛 네트워크?**

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fwcarjdyk0j30rr0m8wjn.jpg)



논문의 Surface에 이런 내용이 나온다. (With 문제 제기로 시작) Residual Neural Network (ResNet) 



![](https://ws4.sinaimg.cn/large/006tNbRwgy1fwcau9ct8mj314t0ohdma.jpg)

**Overfitting의 정의는?**

가지고 있는 Tranning에러는 좋은데, Test는 이상하게 나온다.

**Degradation problem**?

트레이닝도 좋고 테스트도 좋은데 성능이 좋지 않다.

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fwcauj16gej30wt0p0dll.jpg)

**그래서 ResNet에는 Residual network라는 개념이 발생하는데 이때 Residual이 무엇을 의미하는 것인가?**

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fwcavos19nj30xt0lqwin.jpg)입력과 출력의 Demention이 무조건 같아야 한다. 중간에 있는 뉴럴넷은, 왜냐하면 마지막에 더해버리기 때문에

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fwcay02vmdj31210pp13l.jpg)

`y = y + shorcut`  이 부분이 relu를 통해 나온 나머지를 더한 부분

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fwcaythkyzj30zh0obdmk.jpg)

가정을 하고 실행해봤는데, 진짜 맞았다.

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fwcaza0mloj310n0of46x.jpg)

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fwcb091b3xj310r0pswmx.jpg)

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fwcb0uv39fj313x0os4b2.jpg)

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fx8k1jqjeij313e0p8dj0.jpg)

여기서 recetive field를 줄이기 위해서 어떻게 했는가???

![image-20181018142045600](/Users/len/Library/Application Support/typora-user-images/image-20181018142045600.png)

GoogLenet과 같이 1X1을 컨벌루션해서 파라미터를 줄였다. 이후 다시 1x1을 했는데 왜? 다시 256으로 만들기 위해서.



그래서 결과는 ResNet을 안썼을 때는

![image-20181018142145749](/Users/len/Library/Application Support/typora-user-images/image-20181018142145749.png)

성능이 좋지 못했다가, ResNet을 활용하면

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fwcb3qzko0j30z20odwmq.jpg)



그러나 한계가 있다.

레이어 개수가 1000개 넘어가면 문제가 생긴다.

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fwcb4pph33j30u00odadu.jpg)