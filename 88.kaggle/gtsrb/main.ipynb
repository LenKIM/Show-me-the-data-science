{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "N_CLASSES =43\n",
    "RESIZED_IMAGE=(32,32)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00000/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00001/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00002/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00003/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00004/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00005/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00006/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00007/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00008/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00009/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00010/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00011/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00012/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00013/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00014/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00015/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00016/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00017/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00018/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00019/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00020/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00021/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00022/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00023/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00024/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00025/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00026/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00027/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00028/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00029/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00030/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00031/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00032/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00033/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00034/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00035/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00036/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00037/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00038/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00039/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00040/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00041/\n",
      "/Users/len/Show-me-the-data-science/88.kaggle/gtsrb/Images/00042/\n",
      "(39210, 1024)\n",
      "(39210, 43)\n"
     ]
    }
   ],
   "source": [
    "dataset = namedtuple('dataset', ['X', 'y'])\n",
    "\n",
    "def read_dataset_ppm(rootpath, number_labels, resize_to):\n",
    "    \n",
    "    images = np.array([])\n",
    "    labels = np.array([])\n",
    "    imgcnt = 0\n",
    "    resizeimg = []\n",
    "    \n",
    "    for c in range(number_labels):\n",
    "        full_path = rootpath + '/' + format(c, '05d') + '/'\n",
    "        print(full_path)\n",
    "        for img_name in glob.glob(full_path + \"*.ppm\"):\n",
    "            \n",
    "            _image = load_img(img_name)\n",
    "            _image_small = load_img(img_name, target_size=RESIZED_IMAGE, grayscale=True)\n",
    "            x = img_to_array(_image_small)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            images_vector = np.reshape(x, (1,-1))\n",
    "            current_lebel = np.eye(N_CLASSES, N_CLASSES)[c:c+1,:]\n",
    "            \n",
    "            if len(images) is 0:\n",
    "                images = images_vector\n",
    "                labels = current_lebel\n",
    "                \n",
    "            images = np.concatenate((images, images_vector), axis= 0)\n",
    "            labels = np.concatenate((labels, current_lebel), axis=0)\n",
    "            \n",
    "#         print(f'current path: ${full_path}, \\n count: {len(images)}, \\n labels {labels}')\n",
    "        \n",
    "    return dataset(X=images, y=labels)\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "dataset = read_dataset_ppm(current_directory + '/Images', N_CLASSES, RESIZED_IMAGE)\n",
    "print(dataset.X.shape)\n",
    "print(dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset.X[1].reshape(RESIZED_IMAGE))\n",
    "print(dataset.y[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29407, 1024)\n",
      "(29407, 43)\n",
      "(9803, 1024)\n",
      "(9803, 43)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "idx_train, idx_test = train_test_split(range(dataset.X.shape[0]), test_size=0.25, random_state=101)\n",
    "X_train = dataset.X[idx_train]\n",
    "X_test = dataset.X[idx_test]\n",
    "y_train = dataset.y[idx_train]\n",
    "y_test = dataset.y[idx_test]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = [32,32] # 244,244 가로 세로 채널 1\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), input_shape=(32, 32, 1), activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,  activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(N_CLASSES, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "(29407, 32, 32, 1)\n",
      "(29407, 43)\n",
      "(9803, 32, 32, 1)\n",
      "(9803, 43)\n",
      "-----------------\n",
      "Train on 29407 samples, validate on 9803 samples\n",
      "Epoch 1/30\n",
      " 9400/29407 [========>.....................] - ETA: 123s - loss: 3.1057 - acc: 0.2006"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-b48e7adc11f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     callbacks=[early_stopping_callback, checkpointer])\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# 정확도 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/new_env/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/anaconda3/envs/new_env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/anaconda3/envs/new_env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/new_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/new_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/new_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/new_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/anaconda3/envs/new_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/new_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "\n",
    "trainimg = np.reshape(X_train, (X_train.shape[0], 32, 32,1)).astype('float32') / 255.\n",
    "# testimg = to_categorical(y_train, N_CLASSES)\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 32, 32,1)).astype('float32') / 255.\n",
    "# y_test = to_categorical(y_test, N_CLASSES)\n",
    "# trainlabel = to_categorical(trainlabel, nclass)\n",
    "# testlabel = to_categorical(testlabel, nclass)\n",
    "\n",
    "print(\"-----------------\")\n",
    "print(trainimg.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(\"-----------------\")\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=trainimg, y=y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=50, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping_callback, checkpointer])\n",
    "\n",
    "# 정확도 출력\n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, y_test)[1]))\n",
    "# 테스트 셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# 학습셋의 오차\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "# 그래프로 표현\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
