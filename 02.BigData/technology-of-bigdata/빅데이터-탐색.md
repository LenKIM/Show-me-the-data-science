# 빅데이터 탐색

## 1. 하이브

하둡 초창기에는 적재된 데이터를 탐색/분석하기 위한 도구로 맵리듀스(MapReduce)를 주로 이용했지만, 복잡도가 높은 프로그래밍 기법이 필요했고, 이는 접근성이 어렵게 만들었다. 이를 해결하기 위해
SQL과 매우 유사한 방식으로 하둡 데이터에 접근성을 높인 하이브를 개발했다. 그후로 하이브가 오픈소스로 공개되면서 2016년 2월 하이브 2.0이 릴리즈됐고 빅데이터의 가장 대표적인 SQL on Hadoop 

### 주요 구성요소

- CLI - 사용자가 하이브 쿼리를 입력하고 실행할 수 있는 인터페이스
- JDBC/OBDC Driver - 하이브의 쿼리를 다양한 데이터베이스와 연결하기 위한 드라이버를 제공
- Query Engine - 사용자가 입력한 하이브 쿼리를 분석해 실행 계획을 수립하고 하이브 QL을 맵리듀스 코드로 변환 및 실행
- MetaStore - 하이브에서 사용하는 테이블의 스키마 정보를 저장 및 관리하며, 기본적으로 더비(Derby)DB 가 사용되나 다른 DBMS(MySQL, PostgreSQL 등)로 변경 가능.

### 아키텍처

하이브 클라이너트에서 작성한 QL이 맵리듀스 프로그램으로 변환되어 실행된다는 것. 

아래 그림과 같이 CLI, 웹 콘솔 등을 통해 하이브QL을 작성하면 쿼리 엔진(Query Engine)에 있는 SQL파서가 하이브 QL을 맵리듀스 프로그램으로 변환하고, 이 맵리듀스 프로그램이 하둡 클러스터에 전송되어 여러 데이터노드에서 분산 실행된다. 

이 과정에서 하이브의 MetaStore가 매우 중요한 역할을 하는데, 하이브 DW에서 정의한 데이터베이스, 테이블, 파티션 정보 등이 모두 MetaStore에 저장 및 관리되기 때문이다. 

결국 하이브 QL이 작동하면 항상 MetaStore를 참고해 하이브의 런타임환경이 만들어진다. 하이브는 Thrift API를 제공하는데, 클라이언트 프로그램이 API를 호출해 다양한 하이브 액션(Action)을 외부에서 수행할 수 있다.

![](https://ws1.sinaimg.cn/large/006tNc79gy1g22416mbznj30y80u0e83.jpg)

## 2. 스파크

하이브는 복잡한 맵리듀스를 하이브 QL로 래핑해 접근성을 높일 수 있었지만 맵리듀스 코어를 그대로 사용함으로써 성능면에서는 만족스럽지 못했다. 그로 인해 반복작인 대화형 연산 작업에서는 하이브가 적합하지 않았다. 이러한 하이브의 단점을 극복하기 위한 다양한 시도가 있었는데, 그 중 하나가 스파크다.



### 주요 구성요소

- Spark RDD - 스파크 프로그래밍의 기초 데이터셋 모델
- Spark Driver/Executors - Driver는 RDD프로그램을 분산 노드에서 실행하기 위한 Task의 구성, 할당, 계획 등을 수립하고, Executor는 Task를 실행 관리하며, 분산 노드의 스토리지 및 메모리를 참조
- Spark Cluster Manager - 스파크 실행 환경을 구성하는 클러스터 관리자로 Mesos, YARN, Spark Standalone이 있음.
- Spark SQL - SQL 방식으로 스파크 RDD 프로그래밍을 지원
- Spark Streaming - 스트리밍 데이터를 마이크로타임의 배치로 나누어 실시간 처리
- Spark MLib 스파크에서 머신러닝 프로그래밍 지원
- Spark GraphX - 다양한 유형의 네트워크 구조 분석을 지원

### 아키텍처

*고성능 인메모리 분석*

기존 맵리듀스 기반의 하이브 또는 피그의 경우 대량 데이터를 처리할 때 디스크에 적재된 데이터를 대상으로 연산을 수행하게 되어 과도한 디스크 I/O가 발생해 수 분에서 수 시간씩 결과를 기다려야 한다. 하지만 스파크는 이러한 단점을 극복하기 위해 데이터 가공 처리를 인메모리에서 수행함으로써 스파크 SQL, 그 외 대용량 데이터 작업에도 빠른 성능을 보장.

스파크는, 파이썬, 자바, 스칼라, SQL등의 클라이언트 라이브러리를 제공해서 접근성을 높였고, 스파크 코어 연동을 통해 작업 스켸줄링, 메모리 관리, 장애 복구 및 RDD등을 관리할 수 있는 API를 제공한다. 

스파크 엔진은 수천 노드까지 확장 가능한 분산 노드에서 최적의 성능을 낼 수 있는데, 스파크의 분산 노드로 아파치 메소드, 하둡 얀을 이용한다. 데이터 소스 영역은 높은 호환성을 보장하는데 HDFS, HBase, 카산드라, 엘라스틱서치 등을 연결해 이용할 수 있다.

![](https://ws4.sinaimg.cn/large/006tNc79gy1g224du0tuzj30x90u0x6r.jpg)



## 3. 우지

하이브, 피그, 스파크 등을 이용해 빅데이터의 처리, 탐색, 분석하는 과정은 복잡한 선후행 관

계를 맺고 반복적으로 진행된다. 실제 프로젝트에서는 수집 및 적대된 수백 개 이상의 데이터셋을 대산으로 다양한 후처리잡이 데이터 간의 의존성과 무결성을 유지하며 복잡하게 실행된다. 반복적이면서 복잡한 후처리 잡에 시작, 처리 분기, 종료점 등의 액션(Action)으로 구성하는 워크플로가 필요해졌다. 이것이 우지가 발새안 개병.

### 구성요소

- Oozie Workflow - 주요 액션에 대한 작업 규칙과 플로우를 정의

- Oozie Client - 워크플로를 Server에 전송하고 관리하기 위한 환경

  ---

- Oozie Server - 워크플로 정보가 잡으로 등록되어 잡의 실행, 중지, 모니터링 등을 관리

- Control 노드 - 워크플로의 흐름을 제어하기 위한 Start, End, Decision 노드 등의 기능을 제공

- Action 노드 - 잡의 실제 수행 태스크를 정의하는 노드로서 하이브, 피그, 맵리듀스 등의 액션으로 구성

- Coordinator - 워크플로 잡을 실행하기 위한 스케줄 정책을 관리

### 아키텍처

우지의 클라이언트에서 작성한 워크플로는 우지 서버에 저장되며, 관련 워크플로 메타 정보는 RDBMS에서 별도로 관리, 우지 서버에 있는 Coordinator는 우지에 등록된 워크플로를 스케줄링하며, 이때 워크플로 엔진이 Action노드와 Control 노드의 정보를 해석하면서 관련 태스크를 하둡의 클러스터에서 실행시킨다. 주요 Action Task로는 하이브, 피그, 스쿱 등이 있고 관련 Action은 최종적으로 하둡의 맵리듀스 프로그램을 기반으로 작동된다. 그리고 실행 중인 태스크의 라이프 사이클을 우지서버가 시작부터 종료까지 추적되면서 모니터링 정보를 제공



하둡2.x 부터는 YARN을 기반으로 더욱 다양한 어플리케이션을 실행.

![](https://ws4.sinaimg.cn/large/006tNc79gy1g225wh81f0j31e30u0b2a.jpg)



## 4. 휴

빅데이터 탐색/분석은 반복적인 작업이면서 그 과정에서 많은 도구들이 활용된다. 하지만 하둡을 기반으로 하이브, 피그, 우지, 스쿱등알아야 할 기술 요소가 지나치게 많아 업무 담당자 또는 데이터 분석가들이 직접 사용하기에는 많은 어려움이 있다. 빅데이터 기술이 성숙해지면서 이러한 복잡도를 숨기고 접근성을 높인 소프트웨어들이 만들어졌는데, 그중 하나가 바로 클라우데라에서 만든 휴(Hue)이다. 휴는 다양한 하둡의  에코시스템의 기능들을 웹 UI로 통합 제공.

오픈소스로 깃허브로 공개됨,