## 이미지가 주어졌을 때, 각 픽셀이 어디에 속하는지 분류하는 것을 **Semantic Segmentation**

어떤 이미지가 들어왔을 때, 원핫벡터의 길이는 클래스를 길이.

어디에 사용되는가? 자율주행에 사용됨.

4개의 논문을 볼거임

## 01. Fully Convolutional Networks for Semantic Seqmentataion

모든 네트워크가 Fully Conv로 이루어져 FC가 없는것.

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx56n70bljj313y0pigvo.jpg)

기존의 있는 네트워크를 Fully Conv로 만든다는 것은 무엇인지?



![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx56qd0e63j314b0pj14e.jpg)

10 * 10 * 100 이면 만개의 숫자가 들어 있을 것이다. 

당연히, 한 줄로 flatten하면 1만가 들어가 있을 것이다. 그런데, 이를 4096의 사이즈를 만들려고 한다면? 

1 x 1 x 4096 을 만든다면 어떻게?

10000 * 4096을 conv해서 사이즈를 조절한다.

어떤 layer를 컨벌루를 한다는 것은 같은 필터를 가진 것을 컨벌루한다는 의미-

**즉, reshape를 하는 것이 아니라, conv를 통해서 FC한 것과 같은 유사한 사이즈를 만드는 것**

1*1 * 해당 Class 를 만드는 것.

**이렇게 하면 장점**은 입력 이미지 사이즈가 클 경우, 파라미터가 크기 않다.

spicial한 정보를 갖게 된다.

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fx56zfjq59j313b0om465.jpg)

2번째 그림은 3차원 백터

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fx570g6ug9j314e0pjdor.jpg)

이제 결과로부터 heatmap을 할 수 있다.

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx570s4eouj31480px7h2.jpg)

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx57189syuj314u0pxamo.jpg)

그림판에서 이미지를 사이즈를 키우는 것을 interpolotion이라고 하는데, 여기 논문에서는 Deconvolution이라고 한다.

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx573xg1r7j313t0owqba.jpg)

즉, Deconvolution이란, Conv의 완전 역 연산이라고 생각하면 된다.



만약에 우리가 Conv를 한다고 가정했을 때 만약 Stride가 2일 경우에 W / H가 반으로 줄어들게 될 것이다.

그러나, Deconv는 반대 행위- 

어느 한 숫자에다가 Conv 필터만큼 값(스칼라)을 곱한 뒤, 그 이미지에 갖다 놓는다. 그리고 나서 한 칸 옆으로 가서 또 스칼라를 -

overlap되는 부분은 평균을 내서 계산한다.

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fx574h7drxj313t0ph14p.jpg)

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fx5771cpm3j313z0phwqu.jpg)

1/8까지 줄어들면 8배를 키운 Prediction을 만들고, 1/16은 16배 키워서 만들고, 1/32은 32배 키워서 만든 다음에 다 더한다.



너무많은 Conv을 하면 정보가 많이 날라가기 때문에, skip connection이라는 것을 사용한다.



여기서 Skip connection이 배수를 키운 다음에 다 더하는 것이다.

## 02.SEMANTIC IMAGE SEGMENTATION WITH DEEP CON-VOLUTIONAL NETS AND FULLU CONNECTED CRFs

논문은 문제 제기로 시작된다.

기존의 방법(FCN8s에는 2가지 문제가 있다.)

1. Signal Downsampling  
   : 애초 줄어든 정보를 다시 복원을 했을 때 잘 안된다. 라는 것 의미함.
2. Spatial Insensitivity  
   : Spatial한 정보가 많이 줄었기 때문에 윤곽선을 잘 따지 못한다. 그래서 요거를 잘 따기 위해 Conditional random field라는 후처리를 한다.(머신러닝 내용이 아님)

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fx57bd99whj313z0pqh09.jpg)

### Atrous convolution?  

2번 문제점을 해결하기 위해서 사용하는 것.

입력이미지에 비해서 Dense한 CNN을 만들고 싶은 것

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx57fe6d8vj313t0pvard.jpg)

일반적이라면 input feature에 stride padding을 1로 준다면 output은 동일하게 나오겠지만, Atrous Conv은,  좀 더 Dense한 feature map을 만들고 싶은 것.

중간에 0을 넣어서 다리를 얼마나 더 벌릴지 만든다. 즉, 이전의 output보다 더 dense한 featare map을 만드는 것이 목표이다.

5 x 5의 receptive field를 가질 수 있다.

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx57hfchghj314y0pygut.jpg)

Input stride를 output stride보다 크게 만들어서 좀 더 Dense한 Conv를 만드는 것.



**Conditional Random Field**

그래도 맥스폴링이 있어서 작아질텐데, 이걸 키우기 위해서 후처리로 conditional random field를 사용한다.

**일종의 확률 모델이다.**

확률모델에서 RGB픽셀들이 들어 있는데, 각 픽셀마다 라벨이 들어있다. 이 픽셀은 하늘이다, 나무다 등등

**빨간석으로 연결되어 있는 것(Pairwise term을 의미한다.)**

**빨간석으로 연결되어 있는 것은 바로 인접해있는 클래스는 비슷한 feature를 가질 것이라고 가정하는 것.**

**Unary term**이란

지금 픽셀의 정보가 RGB정보가 클래스정보랑 어떻게 연결되어 있는지? 그 확률 정보를 **Unary Term**이라고 한다.

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx57ih9yfej31460pm7gr.jpg)

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx57j8plufj31450plh3f.jpg)

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx57jwqq7hj31470q416e.jpg)

**Conditional Random Field(CRF)** 

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx57kb9teqj314g0q3wy0.jpg)



## 03.Learning Deconvolution Network for semantic Segmentation

이름에서는 Deconvolution이라고 불렸지만, 사실은 럼플링넷이라고 부르는게 더 가깝다.

 ![](https://ws3.sinaimg.cn/large/006tNbRwgy1fx57lu4rrpj30zz0on7ku.jpg)

이 논문도 문제로 제시하는 걸로 시작한다.

1. 기존의 방법론들은 일반적으로 같은 receptive field를 가지게 된다. 이미지를 분류하기 위해서는 굉장히 큰 receptive field가 필요하다. 그러나 이전에 predefined된 내용이 많아서 사진의 내용이 소실되는 일이 발생한다.

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx57mjhlirj313x0po4iu.jpg)

**이 영역은 리셉티브 필드 (receptive field)라고 불리는 초모수 (hyperparameter) 이다.**

큰 물질과 작은 물질을 놓치는 경우가 많다. 그러므로

1 * 1 까지 줄여버린 다음에 복원시켜버리자.

그래서 아예 극단적으로 간다. 

1 x 1 로 만들어 버리고 나중에 다시 키운다.

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fx57p7ifohj31470pydxo.jpg)

이를 해결하기 위해서 **unpooling**을 실시한다.

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx57qf4s31j313w0pn18y.jpg)

unpooling을 통해 물체가 어디에 있었는지 잘 복원 시킨다.

pooling을 반대 연산으로 이라고 생각하자. **여기서 말하는 unpooling은 어려운 행위이다. switch variables를 갖고 동작을 취해야 한다.**

만약 2x2를 maxpooling 한다면 4개의 숫자 중 가장 큰걸 쓸 텐데,

unpooling을 한다고 말한다며느 4개의 칸 중에 하나에 넣어야 하는데, 어디다가 넣어야 하는지 알 수가 없다. 그래서 unpooling을 하기 위해서는 switch variables에 위치 정보를 저장하고 나중에 unpooling할 때 그 위치에 값을 넣고 나머지는 0을 넣는다. 그렇기 때문에 switch variables는 좌우 대칭하면서 값을 저장하고 활용할 수 있다.

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fy60vvefggj30m90e6wni.jpg)

1. BN이 들어가고
2. 일종의 커리큘럼 러닝- 물체 가운데에 있는 이미지를 먼저 학습시키고 난 이후에 좀더 복잡한 위치에 있는 이미지를 학습시킨다.
3. 네트워크자체가 여러개 있다. 이미지안에서 여러 영역을 떼어놓고 subpatch를 얻어서 작업함.

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx57t79u7fj313u0pntj2.jpg)

## 04.DeepLab

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fx57wyiyfuj316x0nstne.jpg)

위 개념들을 활용하고 ASPP라는 것이 추가됨.

문제부터 나열하면 

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fx57xolvhwj313x0pnti5.jpg)

이러한 문제를

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx57ydp3vrj313w0pgnbi.jpg)

해결한 방법.

**여기서는 Atrous spatial pyramid pooling만 살펴본다.**

좀 더 Dense한 파라미터를 넣는다.

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fx57znaytyj314s0pr7jd.jpg)

Atrous Conv과 Deconv의 차이는??

일반적으로 Atrous Conv의 필터는 중간에 0이 껴있어서 사실은 더 큰데, 정의하는 파라미터의 수는 더 적다. 왜냐하면, 필터 중간중간에 0이 들어가 있기 때문이다.

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fx580vr8e7j314c0pygzz.jpg)

이 부분이 피라미드 부분.

이미지 안에서 여러 가지의 크기에 대해서 잡고 싶은 것.

작은 부분은 3x3,  큰 부분은 5 x 5

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fx581l1oz2j313x0psale.jpg)

이미지를 줄여도 알아볼 수 있다.

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fy6193gug1j30lz0ds0wk.jpg)

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fy619nf9i1j30pd0e5n4f.jpg)

----

## Full-Resolution Residual Networks for Semantic Segmentation

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fy61am9uysj30o10e4jym.jpg)

논문의 특징은 큰 흐름이 2개가 있다. 무엇가 줄였다 키웠다 했을 때

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fx589etxpmj310d0p7qd2.jpg)

## 그 외

1. U-Net  
   pix2pix와 같은 GAN에서 많이 사용함.  
   ![](https://ws3.sinaimg.cn/large/006tNbRwgy1fx58cl9rlij30nk0nh790.jpg)
2. Deep contextual networks  
   ![](https://ws4.sinaimg.cn/large/006tNbRwgy1fx58cyre5dj30sh0oadnf.jpg)
3. ![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx58dcegxmj30xb0mgn43.jpg)
4. ![](https://ws2.sinaimg.cn/large/006tNbRwgy1fx58e4vp57j31100n1gu3.jpg)
5. 
6. 