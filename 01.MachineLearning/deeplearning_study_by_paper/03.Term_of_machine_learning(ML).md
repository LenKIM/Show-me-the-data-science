# 기계학습에 대한 용어 정의하기.



### 00. input?

뉴렐넷이란? 어떤 연결이 되어있는 것 (= 흘러가는 것)

이미지가 될 수도 있고 숫자도 될 수 있고~

### 01. Output / Class / Label

우리가 4개의 물체만 다루겠다~~~ 라는 식으로 정의해놓는다.

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fwb7eawczqj313c0o0wu7.jpg)위 같이 0 과 1로 나눈걸 one-hot ending이라고 한다.

### 02. Traiaing / Learning

https://ws4.sinaimg.cn/large/006tNbRwgy1fwb7gju6o5g30vu0ks4r6.gif

### 03.Dataset

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fwb7i6wwubj30tw0lstns.jpg)

철저하게 **Training Data**와 무관한 데이터를 **Validation Data**라고 한다.

어떤 활성함수를 쓸거다. 어떤 레이어를 할거다. 등 configulation을 할 수 있는 부분을 **Validation Data**라고 부른다.

### 04.Neuron

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fwb7jt41qoj30wo0oqwkq.jpg)

### 05.Basic single layer network

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fwb7kt73qsj313a0p2482.jpg)

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fwb7mlxvxrj30yq0og11c.jpg)

단순히 계산하는 것을 말한다.

### 06.(Neural) Network

여러개의 레이어가 있을 수 있는데, 

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fwb7ox7bcgj314s0oagvh.jpg)



**레이어를 1000개 쌓아도 activation function이 없다면 1개를 쌓는 것과 같다.**

### 07.Multi-Layer Perceptron / dence-Layer 

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fwb7puchlyj30zq0oqn1s.jpg)

### 08. Activation Function

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fwb7qc9rfuj30zq0lq0wg.jpg)



시그모이드는 0,1로 할때

thanh은 -와 +

ReLU는 확률

softplus 회귀문제를 풀때 장점을 가짐.

### 09. Epoch/Batch size / Iteration

여기서 epoch은 한번 다 사용했을때 단위. 2000만개의 date가 한번 다 돌 았을때,

2000만개가 너무 많으면 그 중에 일부만 쓰는 걸 Batch size

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fwb7sn0n0fj311m0omti7.jpg)

### 10.Cost function

우리가 loss를 줄이고자하는 사용하는 함수

왜? Cost function이 좋은가? 미분이 가능한가? 경사적 하강법같은걸 Cost function이라고 한다. 자연어 처리에서는 강화학습을 많이 사용한다.  
***우리는 Cost function에 집중해서 어떻게 loss을 줄일 수 있는가를 연구해야 한다.***

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fwb7v1040xj312u0o2tds.jpg)

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fwb7uqvbs2j30z40p014c.jpg)

