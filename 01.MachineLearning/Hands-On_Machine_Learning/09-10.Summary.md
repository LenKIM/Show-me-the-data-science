## 목차

~~9장. 텐서플로 시작하기~~

~~9.1 설치~~

9.2 첫 번째 계산 그래프를 만들어 세션에서 실행하기

9.3 계산 그래프 관리

9.4 노드 값의 생애주기

9.5 텐서플로를 이용한 선형 회귀

9.6 경사 하강법 구현

9.7 훈련 알고리즘에 데이터 주입

9.8 모델 저장과 복원

~~9.9 텐서보드로 그래프와 학습 곡선 시각화하기~~

9.10 이름 범위

9.11 모듈화

9.12 변수 공유

9.13 연습문제

 

~~10장. 인공 신경망 소개~~

~~10.1 생물학적 뉴런에서 인공 뉴런까지~~

~~10.2 텐서플로의 고수준 API로 다층 퍼셉트론 훈련하기~~

~~10.3 텐서플로의 저수준 API로 심층 신경망 훈련하기~~

~~10.4 신경망 하이퍼파라미터 튜닝하기~~

10.5 연습문제 



## 9.2 첫 번째 계산 그래프를 만들어 세션에서 실행하기

**계산 그래프 만들기.**

```python
import tensorflow as tf

x = tf.Variable(3, name="x")
y = tf.Variable(3, name="y")
f = x*x*y + y + 2
```

계산 그래프를 만들었으면 마지막에 이 내용이 실행될까?



Nope.



이 계산 그래프를 평가하려면 텐서플로 **세션**  을 시작하고 변수를 초기화한 다음 f를 평가해야 한다.



```python
sess = tf.Session()
sess.run(x.initializer)
sess.run(y.initializer)

result = sess.run(f)
print(result)
# 32
sess.close
```



Full code

```python
import tensorflow as tf

x = tf.Variable(3, name="x")
y = tf.Variable(3, name="y")
f = x*x*y + y + 2


sess = tf.Session()
sess.run(x.initializer)
sess.run(y.initializer)

result = sess.run(f)
print(result)

sess.close()
```



조금더 이쁘게

```python
import tensorflow as tf

init = tf.global_variables_initializer()
init.run()

sess = tf.InteractiveSession() # init 노드 준비
result = f.eval()
print(result)
sess.close()
```



*정리하면 텐서플로 프로그램은 두 부분으로 나뉩니다.*

첫 부분은 **계산 그래프**를 만들고(**구성 단계**)

두 번째 부분은 이 그래프를 실행(**실행 단계**) - sess.run()



## 9.3 계산 그래프 관리

```python
x1 = tf.Variable(1)
x1.graph is tf.get_default_graph()

# True
```

```python
graph = tf.Graph()
with graph.as_default():
    x2 = tf.Variable(2)
    
x2.graph is graph # True

x2.graph is tf.get_default_graph() # False
```

## 9.4 노드 값의 생애주기

```python
w = tf.constant(3)
x = w + 2
y = x + 5
z = x * 3

with tf.Session() as sess:
    print(y.eval()) # 10
    print(z.eval()) # 15
```

*Nono*  w와 x가 두번 평가 되면 안좋아~

```python
w = tf.constant(3)
x = w + 2
y = x + 5
z = x * 3

with tf.Session() as sess:
    y_val, z_val = sess.run([y,z])
    print(y.eval()) # 10
    print(z.eval()) # 15
```

***단일 프로세스 텐서플로에서는 같은 그래프를 사용하더라도 여러 세선에서 어떤 상태도 공유하지 않습니다.(각 세션은 모든 변수에 대해 고유한 복사본을 가집니다.)***



## 9.5 텐서플로를 이용한 선형 회귀

- 텐서플로에서 입력과 출력은 텐서(tensor)라는 다차원 배열이며, 넘파이 배열과 비슷하게 텐서는 데이터 타입과 크기를 가집니다.

```python
import numpy as np
from sklearn.datasets import fetch_california_housing

housing = fetch_california_housing()
m, n = housing.data.shape
housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]

X = tf.constant(housing_data_plus_bias, dtype= tf.float32, name='X')
y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name='y')

XT = tf.transpose(X)
theta = tf.matul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)), XT), y)

with tf.Session() as sess:
    theta_value = theta.eval()
```

이렇게 계산 그래프를 만들고 활용하는데 발생하는 장점은?

GPU가 있는 경우 자동으로 GPU에서 실행된다는 것.



## 9.6 경사 하강법 구현

### 1. 직접 그래디언트 계산

```python
n_epochs = 1000
learning_rate = 0.01

X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name="X")
y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name="y")
theta = tf.Variable(tf.random_uniform([n+1,1], -1.0 , 1.0), name= "theta") # 난수를 담은 텐서를 생성하는 노드를 그래프에 생성, 넘파이의 rand()함수처럼 크기와 난수의 범위를 입력 받습니다.
y_pred = tf.matmul(X, theta, name="predictions")

error = y_pred - y
## mse = tf.reduce_mean(tf.square(error), name= "mse") ##
## gradients = 2/m * tf.matmul(tf.transpose(X), error) ##
training_op = tf.assign(theta, theta - learning_rate * gradients) # 변수에 새로운 값을 할당하는 노드를 생성 / 여기서는 배치 경사 하강법의 스템

init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init)
    
    for epoch in range(n_epochs):
        if epoch % 100 == 0:
            print("Epoch", epoch, "MSE =", mse.eval())
        sess.run(training_op)
    best_theta = theta.eval()
```

### 2. 자동 미분 사용

```python
gradients = tf.gradients(mse, [theta])[0]
```

gradients() 함수는 하나의 연산(여기서는 mse)와 변수 리스트(여기서는 theta)를 받아 각 변수에 대한 연산의 그래디언트를 계산하는 새로운 연산을 만든다.

### 3. 옵티마이저 사용

```python
optimizer  = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
trainig_op = optimizer.minimize(mse)
```

## 9.7 훈련 알고리즘에 데이터 주입

미니 배치 경사 하강법을 구현하기 위해 이전 코드를 변경해보면, 매 반복마다 X와 y를 다음번 미니배치로 바꿔야 한다. 이를 해결하기 위한 가장 간단한 방법은 **Placeholder노드를 사용하는 것**. 이 노드는 실제로 아무 계산도 하지 않는 특수한 노드이지만,



이 노드는 전형적으로 훈련을 하는 동안 텐서플로에 훈련 데이터를 전달하기 위해 사용된다. 실행시 플레이스홀더에 값을 지정하지 않으면 예외가 발생합니다.

```python
A = tf.placeholder(tf.float32, shape=(None,3))
B = A + 5
with tf.Session() as sess:
    B_val_1 = B.eval(feed_dict= {A: [[1,2,3]]})
    B_val_2 = B.eval(feed_dict= {A: [[4,5,6], [7,8,9]]})
    
print(B_val_1) # 6,7,8
print(B_val_2) # 9,10,11 / 12,13,14
```

## 9.8 모델 저장과 복원

모델을 훈련시키고 나면 필요할 때 다시 쓸 수 있도록 (다른 프로그램에서 사용하거나 다른 모델과 비교할 때 등) 모델 파라미터를 디스크에 저장해야 한다.

훈련하는 동안 일정한 간격으로 체크포인트를 저장해두면 컴퓨터가 훈련 중간에 문제를 일으켜도 처음부터 다시 시작하지 않고 마지막 체크포인트부터 이어나갈 수 있다.

텐서플로에서 모델을 저장하는 일은 매우 쉽다. 구성 단계의 끝에서 Saver 노드를 추가하고, 실행 단게에서 모델을 저장하고 싶을 때 save() 메서드에 세션과 체크포인트 파일의 경로를 전달하여 호출하면 됩니다.

```python
[...]
theata = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0, name="theta"))
[...]

init = tf.global_variables_initializer()
saver = tf.train.Saver()

with tf.Session() as sess:
    sess.run(init)
    
    for epoch in range(n_epoches):
        if epoch % 100 == 0:
            save_path = saver.save(sess, "/tmp/my_model.ckpt")
        sess.run(training_op)
    best_theta = theta.eval()
    save_path = saver.save(sess, "/tmp/my_model_final.ckpt")
```



복원은?

```python
with tf.Session() as sess:
    saver.restore(sess, "/tmp/my_model_final.ckpt")
    [...]
```



## 9.10 이름 범위



왜 이름범위를 정해야 될까?



신경망처럼 매우 복잡한 모델을 다룰 때는 계산 그래프는 수천 개의 노드로 인해 어질러지기 쉽습니다. 이를 피하려면 이름범위(name scope)를 만들어 관련 있는 노드들을 그룹으로 묶어야 합니다.

예를 들어 이전 코드를 수정해 "loss"이름 범위 안에 있는 error와 mse를 정의해보자.

```python
with tf.name_scope("loss") as scope:
    error = y_pred - y
    mse = tf.reduce_mean(tf.square(error), name="mse")
```

## 9.11 모듈화

두 개의 ReLU 출력을 더하는 그래프를 만든다고 가정해보자. ReLU는 입력에 대한 선형 함수로서 양수는 그대로 출력하고 음수일 때는 0을 출력

```python
## relu
n_features = 3
X = tf.placeholder(tf.float32, shape=(None, n_features), name="X")

w1 = tf.Variable(tf.random_normal((n_features, 1)), name="weights1")
w2 = tf.Variable(tf.random_normal((n_features, 1)), name="weights2")
b1 = tf.Variable(0.0, name="bias1")
b2 = tf.Variable(0.0, name="bias2")

z1 = tf.add(tf.matmul(X, w1), b1, name="z1")
z2 = tf.add(tf.matmul(X, w1), b1, name="z2")

relu1 = tf.maximum(z1, 0., name='relu1')
relu2 = tf.maximum(z2, 0., name='relu2')

ouput = tf.add(relu1, relu2, name="output")
```

이걸 모듈로 만들면?

```python
def relu(X):
    w_shape = (int(X.get_shape()[1]),1)
    w = tf.Variable(tf.random_normal(w_shape), name="weights")
    b = tf.Variable(0.0, name="bias")
    z = tf.add(tf.matmul(X,w), b, name="z")
    return tf.maximum(z, 0., name='relu')

n_features = 3
X = tf.placeholder(tf.float32, shape=(None, n_features), name="X")
relus = [relu(X) for i in range(5)]
output = tf.add_n(relus, name="output")
```

## 9.12 변수 공유

그래프의 여러 구성 요소 간에 변수를 공유하고 싶다면, 간단한 해결 방법은 변수를 먼저 만들고 필요한 함수에 매개변수로 전달하는 것이다. 예를 들어 ReLU의 임곗값을 조정하기 위해 threshold 변수를 모든 ReLU에 공유하려 한다고 합시다.(현재는 0으로 하드코딩되어 있습니다.) 먼저 변수를 만들고 relu()함수에 전달합니다.

```python
def relu(X, threshold):
    with tf.name_scope("relu"):
        [...]
        return tf.maximum(z, threshold, name="max")
threshold = tf.Variable(0.0, name="threshold")
X = tf.placeholder(tf.float32, shape=(None, n_features),name="X")
relus = [relu(X, threshold) for i in range(5)]
output = tf.add_n(relus, name="output")
```



threshold 변수로 모든 ReLU의 임계값을 조절할 수 있다. 하지만 이런 공유 변수가 많으면 항상 매개변수로 전달해야 하므로 번거로워집니다. 많은 사람이 모델에 있는 모든 변수를 담을 파이썬 딕셔너리를 만들고 함수마다 이를 전달하는 방식을 사용합니다.

```python
def relu(X):
    with tf.name_scope("relu"):
        if not hasattr(relu, "threshold"):
            relu.threshold = tf.Variable(0.0, name="threshold")
            [...]
		    return tf.maximum(z, relu.threshold, name='relu')
```

위 같이 할 수도 있지만 텐서플로에서는 더 좋은 방법을 제공해주는데,



기본 아이디어는 get_variable() 함수를 사용해 공유 변수가 아직 존재하지 않을 때는 새로 만들고 이미 있을 때는 재사용하는 것입니다. 상황에 맞는 동작(생성 또는 재사용)은 현재 variable_scope() 의 속성값으로 결정됩니다. 예를 들어 다음 코드는 relu/threshold 변수를 생성할 것입니다.(shape=()이므로 스칼라 변수이고 초깃값은 0.0입니다.)

```python
with tf.variable_scope("relu"):
    threshold = tf.get_variable("threshold", shape=(),
                               initalizer = tf.constant_initializer(0.0))
```

만약 이 변수가 이전의 get_variable( ) 호출에서 이미 생성되었다면 이 코드는 예외를 발생할 것이고, 이런 동작 방식은 실수로 변수를 사용하는 것을 막아줍니다. 변수를 재사용하고 싶다면  reuse속성을 True로 지정하면 됨.

```python
def relu(X):
    with tf.name_scope("relu"):
        if not hasattr(relu, "threshold"):
            relu.threshold = tf.Variable(0.0, name="threshold")
            [...]
		    return tf.maximum(z, relu.threshold, name='relu')

        
X = tf.placeholder(tf.float32, shape=(None, n_features), name= "X")
with tf.variable_scope("relu"):
    threshold = tf.get_variable("threshold", shape=(), initalizer= tf.constant_initalizer(0.0))
relus = [relu(X) for relu_index in range(5)]
output = tf.add_n(relus, name="output")
```





# 연습문제

1. **계산을 직접 실행하지 않고 계산 그래프를 만드는 주요 장점과 단점은 무엇?**

   - 장점
     - 텐서플로가 자동으로 그래디언트를 계산할 수 있다.
     - 텐서플로가 여러 스레드에서 연산을 병렬로 실행할 수 있다.
     - 동일한 모델을 여러 장치에 걸쳐 실행시키기 편리합니다.
     - 내부 구조를 살피기 쉽습니다. 예를 들어 텐서보드에서 모델을 시각화할 수 있다.
   - 단점
     - 익숙하게 다루려면 시간 필요
     - 단계별 디버깅 어려움

2. **a_val =a.eval(session=sess) 와 a_val = sess.run(a) 는 동일한 문장? O**  

3. **a_val, b_val = a.eval(session=sess), b.eval(session=sess)와 a_val, b_val = sess.run([a,b])는 동일한 문장인가?**  

   - X
     - 첫 번째 문장은 그래프를 두 번(한번은 a, 한번은 b) 실행하지만, 두 번째 문장은 그래프를 한 번만 실행합니다. 이 연산(또는 의존하는 다른 연산이) 부수효과를 일으키며 결과가 달라질 것.

4. **같은 세션에서 두 개의 그래프를 실행 수 있나?**  
   X, 두 개의 그래프를 하나로 합쳐야 함.

5. **만약 변수 w를 가진 그래프 g를 만들고 스레드 두 개를 시작해 각 스레드에서 동일한 그래프 g를 사용하는 세션을 열면, 각 세션은 변수 w를 따로 가지게 될까? 아니면 공유하게 될까?**  

   공유함

6. **변수는 언제 초기화되고 언제 소멸되나?**  
   변수는 초기화 함수가 호출 될 때, 세션이 종료될 때 소멸됨.  
   분산 텐서플로에서는 변수가 클러스터에 있는 컨테이너에 존재하기 때문에 세션을 종료해도 변수가 소멸되지 않으며 변수를 삭제하려면 컨테이너를 리셋해야 합니다.

7. **플레이스홀더와 변수의 차이점은 무엇?**  

   - 변수는 값을 가진 연산 - 변수를 실행하면 값이 반환됨. 변수를 실행하기 전에 초기화해야 한다. 또한 변수의 값을 바꿀 수있다. 변수는 상태를 가진다. 즉, 그래프를 연속해서 실행할 때 변수는 동일한 값을 유지합니다. 일반적으로 변수는 모델 파라미터를 저장하는 데 사용하지만 다른 목적으로도 쓰인다(예를 들면 전체 훈련 스텝을 카운트하기 위해)
   - 플레이스 홀더는 많은 일을 하지는 않지만, 표현하려는 텐서의 크기와 타입에 관한 정보를 가지고 있을 뿐 아무런 값도 가지고 있지 않습니다. 실제로 플레이스홀더에 의존하고 있는 연산을 평가하려면 훌레이스홀더의 값을(feed_dict 매개변수를 통해) 텐서플로에 제공해야 합니다. 그러지 않으면 예외가 발생합니다. 일반적으로 플레이스홀더는 실행 단계에서 텐서플로에 훈련 데이터와 테스트 데이터를 주입하기 위해 사용됩니다. 또한 변수의 값을 바꾸기 위해 할당 연산 노드에 값을 전달하는 용도로도 사용됩니다.

8. **플레이스홀더에 의존하는 연산을 평가하기 위해 그래프를 실행할 때 플레이스홀더에 값을 주입하지 않으면 어떻게 될까? 플레이스홀더에 의존하지 않는 연산이라면 어떻게 될까요?**  
   예외 발생함. 의존하지 않는 연산이라면 예외 발생 안함.

9. **그래프를 실행할 때 어떤 연산자의 출력값을 주입할 수 있나? 아니면 플레이스홀더의 값만 가능한가?**  

10. **(실행 단계에서) 변수에 원하는 값을 어떻게 설정?**

    그래프를 구성할 때 변수의 초기화 값을 지정할 수 있고, 나중에 실행 단계에서 변수의 초기화 함수를 실행할 때 초기화될 것입니다. 실행 단계에서 변수의 값을 변경하는 간단한 방법은(구성 단계에서) tf.assign( )을 이용한 할당 노드를 만들고 매개변수로 변수와 플레이스홀더를 전달하는 것입니다. 그리고 실행 단계에서 플레이스홀더를 사용해 변수의 새로운 값을 주입하여 할당 연산을 실행

    ```python
    import tensorflow as tf
    
    x = tf.Variable(tf.random_uniform(shape=(), minval=0.0, maxval=1.0))
    x_new_val = tf.placeholder(shape=(), dtype=tf.float32)
    x_assign = tf.assign(x, x_new_val)
    
    with tf.Session():
        x.initalizer.run()
        print(x.eval())
        x_assign.eval(feed_dict={x_new_val: 5.0})
        print(x.eval()) # 5.0
    ```

11. **후진 모드 자동 미분으로 변수 10개에 대한 비용 함수의 그래디언트를 계산하려면 그래프를 몇 번 순회해야 하는가? 전진 모드 자동 미분이나 기호 미분의 경우는 어떨까요?**

12. 텐서 플로를 사용해 미니배치 경사 하강법으로 로지스틱 회귀를 구현해보기. 그리고 부가기능을 구차해보기


    - (손쉽게 재사용할 수 있도록) logistic_regression()안에 그래프 정의
    - 훈련하는 동안 Saver로 체크포인트를 정기적으로 저장, 그리고 훈련 마지막에 최종 모델을 저장
    - 텐서보드에서 그래프가 일목요연하게 보이도록 이름 범위를 사용해 그래프를 정의
    - 서머리를 추가해 텐서보드에서 학습 곡선을 시각화
    - 학습률이나 미니배치 크기 같은 하이퍼파라미터를 바꿔보고 학습 곡선의 형태를 살펴보기



## 10. 연습문제

1. **초창기 인공 뉴런을 사용해 A +(XOR) B 를 계산하는 인공신경망을 그려보기.** 

   ![](https://ws3.sinaimg.cn/large/006tNbRwgy1fyoqm63lcyj30y40k4aez.jpg)

2. **고전적인 퍼셉트론(즉, 퍼셉트론 훈련 알고리즘으로 훈련된 단일 TLU) 보다 로직스틱 회귀 분류기가 일반적으로 선호하는 이유는 무엇인가요? 퍼셉트론을 어떻게 수정하면 로지스틱 회귀 분류기가 동등하게 만들 수 있나?**

   고전적인 퍼셉트론은 데이터셋이 전형적으로 구분될 때만 수렴하고 클래스 확률을 추정할 수 없습니다. 이와는 반대로 로지스틱 회귀 분류기는 데이터셋이 전형적으로 구분되지 못해도 좋은 솔루션으로 수렴하고 클래스 확률을 출력합니다. 퍼셉트론의 활성화 함수를 로지스틱 함수로(또는 여러 개의 뉴런일 경우 소프트맥스 활성화 함수로 ) 바꾸고, 경사 하강법을 사용하여(또는 크로스 엔트로피 같은 비용 함수를 최소화하는 다른 최적화 알고리즘을 사용하여) 훈련시키면 로지스틱 회귀 분류기와 동일하게 됩니다.

3. **왜 초창기의 다층 퍼셉트론을 훈련시킬 때 로지스틱 활성화 함수가 핵심 요소 였나?**  

   로지스틱 활성화 함수의 도함수는 어디에서나 0이 아니어서 경사 하강법이 항상 경사를 따라 이동할 수 있으므로 초창기 MLP의 핵심 요소 였습니다. 활성화 함수가 계단 함수일 때는 경사가 없기 때문에 경사 하강법이 이동할 수 없습니다.

4. **유명한 활성화 함수 네 가지는 무엇?**  

   계단 함수, 로지스틱, 하이퍼볼릭 탄젠트, ReLU

5. **10개의 통과 뉴런으로 된 입력층, 50개의 뉴런으로 된 은닉층, 그리고 3개의 뉴런으로 된 출력층으로 구성된 다층 퍼셉트론이 있다고 가정하자. 모든 뉴런은 ReLU 활성화 함수를 사용합니다.**

   - 입력 행렬 X의 크기는 얼마? m X 10 여기서 m은 훈련 배치의 크기

   - 은닉층의 가중치 백테 W(h) 와 편향 벡터 b(h)의 크기는 얼마? 10 X 50 , 50

   - 출력층의 가중치 백터W(o) 와 편향 벡터 b(o)의 크기는 얼마? 50 * 3, 3

   - 네트워크의 출력 행렬 Y의 크기는 얼마인가요? m * 3

   - X, W(h), b(h), W(o), b(o)의 함수로 네트워크의 출력 행렬 Y를 계산하는 식을 써보기.

     ![](https://ws1.sinaimg.cn/large/006tNbRwgy1fyoqtomt1mj30vq05eq4x.jpg)

6. 스펨 메일을 분류하기 위해서는 출력층에 몇 개의 뉴런이 필요할까? 출력층에 어떤 활성화 함수를 사용해야 될까? MNIST문제라면 출력층에 어떤 활성화 함수를 사용하고 뉴런은 몇 개가 필요할까? 1개, 확률을 추정해야 하므로 로지스틱 함수,

7. **역전파란 무엇이고 어떻게 작동하는가? 역전파와 후진 모드 자동 미분의 차이점은 무엇인가요?**

   // TODO

8. **다층 퍼셉트론에서 조정할 수 있는 하이퍼파라미터를 모두 나열해보세요. 훈련 데이터에 다층 퍼셉트론이 과대접합되었다면 이를 해결하기 위해 하이퍼파라미터를 어떻게 조정해야 할까요?**

   MLP에서 바꿀 수 있는 하이퍼파라미터는 은닉층 수, 각 은닉층의 뉴런 수, 각 은닉층과 출력층에서 사용하는 활성화 함수.
   만약 과대접합되었을 때는 은닉층 수와 각 은닉층에 있는 뉴런 수를 줄여볼 수 있다.

9. **깊은(deep) 다층 퍼셉트론을 MNIST 데이터셋에 훈련시키고 98% 정확도를 얻을 수 있는지 확인해보세요. 9장의 마지막 연습문제에서와 같이 모든 모든 부가 기능을 추가해보세요.(즉, 체크포인트를 저장하고, 중지되었을 때 마지막 체크포인트를 복원하고, 서머리를 추가하고 텐서보드를 사용해 학습 곡선을 그려보세요.)**