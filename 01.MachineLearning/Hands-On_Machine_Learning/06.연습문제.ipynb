{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 백만 개의 샘플을 가진 훈련 세트에서 (규제 없이) 훈련시킨 결정 트리의 깊이는 대략 얼마일까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " = log($10^6$) 이므로 거의 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 한 노드의 지니 불순도가 보통 그 부모 노드보다 작을까요, 아니면 클까요? 일반적으로 작거나 클까요, 아니면 항상 작거나 클까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= 지니 불순도 계산은  1 - 시그마 $p_ik$ 이므로 갈수록 작아 질 것. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 결정 트리가 훈련 세트에 과대적합되었다면 max_depth를 줄이는 것이 좋을까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= 네, 복잡하기 때문에 복잡도를 줄여야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 결정 트리가 훈련 세트에 과소적합되었다면 입력 특성의 스케일을 조정하는 것이 좋을까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= 상관없을 듯, 스케일을 조정하는건 복잡한 연산에서 실행하는 것이기 때문에.\n",
    "정답은, 결정 트리에서 입력 특성의 스케일을 조정하는 것은 아예 낭비라고 판단함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 백만 개의 샘플을 가진 훈련 세트에 결정 트리를 훈련시키는 데 한 시간이 걸렸다면, 천만 개의 샘플을 가진 훈련 세트에 결정 트리를 훈련시키는 데는 대략 얼마나 걸릴까요?\n",
    "\n",
    "= 결정 트리 훈련의 계산 복잡도는 $O(n * m * log(m)$ 이다. 그러므로 훈련 세트의 크기에 10을 곱하면 훈련 시간은 K = (n * 10m * log(10m))/(n * m * log(m)) = 10 * log(10m) / log(m). 만약 m = $10^6$ = 20 이면 K는 11.7정도 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 십만 개의 샘플을 가진 훈련 세트가 있다면 presort=True로 지정하는 것이 훈련 속도를 높일까요?\n",
    "\n",
    "= 아니요. 수천 개 미만일 때만 훈련 세트를 사전에 정렬하여 훈련 속도를 높일 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. moons 데이터셋에 결정 트리를 훈련시키고 세밀하게 튜닝해보세요.  \n",
    "    a. make_moons (n_samples=1000, noise=0.4 )를 사용해 데이터셋을 생성합니다.  \n",
    "    b. 이를 train_test_split ( )을 사용해 훈련 세트와 테스트 세트로 나눕니다.  \n",
    "    c. DecisionTreeClassifier의 최적의 매개변수를 찾기 위해 교차 검증과 함께 그리드 탐색을 수행합니다(GridSearchCV를 사용하면 됩니다). 힌트: 여러 가지 max_leaf_ nodes 값을 시도해보세요.  \n",
    "    d. 찾은 매개변수를 사용해 전체 훈련 세트에 대해 모델을 훈련시키고 테스트 세트에서 성능을 측정합니다. 대략 85~87%의 정확도가 나올 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "(1000,)\n",
      "(750, 2)\n",
      "(750,)\n",
      "(250, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/new_env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], 'min_samples_leaf': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xm, ym = make_moons(n_samples=1000, noise=0.4, random_state=53)\n",
    "\n",
    "Xm_train, Xm_test, ym_train, ym_test = train_test_split(Xm, ym, random_state=53)\n",
    "\n",
    "print(Xm.shape)\n",
    "print(ym.shape)\n",
    "print(Xm_train.shape)\n",
    "print(ym_train.shape)\n",
    "print(Xm_test.shape)\n",
    "deep_tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "parameters = {'max_leaf_nodes': [2,3,4,5,6,7,8,9,10,11,12,13,14], 'min_samples_leaf': [2,3,4,5,6,7,8,9,10,11,12]}\n",
    "gs_cv = GridSearchCV(deep_tree_clf, param_grid=parameters)\n",
    "gs_cv.fit(Xm_train, ym_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=10,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "def plot_decision_boundary(clf, X, y, axes=[0, 7.5, 0, 3], iris=True, legend=False, plot_training=True):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if not iris:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    if plot_training:\n",
    "        plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", label=\"Iris-Setosa\")\n",
    "        plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", label=\"Iris-Versicolor\")\n",
    "        plt.plot(X[:, 0][y==2], X[:, 1][y==2], \"g^\", label=\"Iris-Virginica\")\n",
    "        plt.axis(axes)\n",
    "    if iris:\n",
    "        plt.xlabel(\"꽃잎 길이\", fontsize=14)\n",
    "        plt.ylabel(\"꽃잎 너비\", fontsize=14)\n",
    "    else:\n",
    "        plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "        plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)\n",
    "    if legend:\n",
    "        plt.legend(loc=\"lower right\", fontsize=14)\n",
    "        \n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(image_path(fig_id) + \".png\", format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(11, 4))\n",
    "plt.subplot(121)\n",
    "plot_decision_boundary(gs_cv, Xm_train, ym_train, axes=[-1.5, 2.5, -1, 1.5], iris=False, plot_training=False)\n",
    "plt.title(\"min_samples_leaf = {}\".format(gs_cv.best_params_['min_samples_leaf']), fontsize=14)\n",
    "\n",
    "# save_fig(\"min_samples_leaf_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 랜덤 포레스트를 만들어보세요.  \n",
    "    a. 이전 연습문제에 이어서, 훈련 세트의 서브셋을 1,000개 생성합니다. 각각은 무작위로 선택된 100개의 샘플을 담고 있습니다. 힌트: 사이킷런의 ShuffleSplit을 사용할 수있습니다.  \n",
    "    b. 앞에서 찾은 최적의 매개변수를 사용해 각 서브셋에 결정 트리를 훈련시킵니다. 테스트 세트로 이 1,000개의 결정 트리를 평가합니다. 더 작은 데이터셋에서 훈련되었기 때문에 이 결정 트리는 앞서 만든 결정 트리보다 성능이 떨어져 약 80%의 정확도를 냅니다.  \n",
    "    c. 이제 마술을 부릴 차례입니다. 각 테스트 세트 샘플에 대해 1,000개의 결정 트리 예측을 만들고 다수로 나온 예측만 취합니다(사이파이의 mode ( ) 함수를 사용할 수 있습니 다). 그러면 테스트 세트에 대한 다수결 예측 majority - vote prediction 이 만들어집니다.  \n",
    "    d. 테스트 세트에서 이 예측을 평가합니다. 앞서 만든 모델보다 조금 높은(약 0.5~1.5% 정도) 정확도를 얻게 될 것입니다. 축하합니다. 랜덤 포레스트 분류기를 훈련시켰습 니다!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xm, ym = make_moons(n_samples=100000, noise=0.4)\n",
    "\n",
    "Xm_train, Xm_test, ym_train, ym_test = train_test_split(Xm, ym)\n",
    "\n",
    "n_trees = 1000\n",
    "n_instances = 100\n",
    "\n",
    "mini_sets = []\n",
    "\n",
    "rs = ShuffleSplit(n_splits=n_trees, test_size=len(Xm_train) - n_instances)\n",
    "for mini_train_index, mini_test_index in rs.split(Xm_train):\n",
    "    x_mini_train = Xm_train[mini_train_index]\n",
    "    y_mini_train = ym_train[mini_train_index]\n",
    "    mini_sets.append((x_mini_train, y_mini_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7892547599999999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 각각 학습 시킨다.\n",
    "forest = [clone(gs_cv.best_estimator_) for _ in range(n_trees)]\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for tree, (X_mini_train, y_mini_train) in zip(forest, mini_sets):\n",
    "    tree.fit(X_mini_train, y_mini_train)\n",
    "    \n",
    "    y_prediction = tree.predict(Xm_test)\n",
    "    accuracy_scores.append(accuracy_score(ym_test, y_prediction))\n",
    "    \n",
    "np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. 이제 마술을 부릴 차례입니다. 각 테스트 세트 샘플에 대해 1,000개의 결정 트리 예측을 만들고 다수로 나온 예측만 취합니다(사이파이의 mode ( ) 함수를 사용할 수 있습니 다). 그러면 테스트 세트에 대한 다수결 예측 majority - vote prediction 이 만들어집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.empty([n_trees, len(Xm_test)], dtype=np.uint8)\n",
    "\n",
    "for tree_index, tree in enumerate(forest):\n",
    "    y_pred[tree_index] = tree.predict(Xm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "y_pred_majority_votes, n_votes = mode(y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. 테스트 세트에서 이 예측을 평가합니다. 앞서 만든 모델보다 조금 높은(약 0.5~1.5% 정도) 정확도를 얻게 될 것입니다. 축하합니다. 랜덤 포레스트 분류기를 훈련시켰습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82644"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ym_test, y_pred_majority_votes.reshape([-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
