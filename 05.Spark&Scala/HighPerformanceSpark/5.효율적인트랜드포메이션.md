# Goal

RDD에는 6가지 타입이 있고, 각각의 타입에는 자신만의 속성들과 20여 가지의 다른 트랜스포메이션 함수를 포함한다.

그러므로, 어떤식의 연계가 효과적인지 아닌지, 여러 개가 이어진 트랜스포메이션이 가능한 한 띄어난 성능을 발휘라며녀 어떻게 해야 되는지 등을 살펴볼것.



## 좁은 트렌스포메이션 vs 넓은 트랜스포메이션

- 넓은 트랜스포메이션은 셔플을 요구하는 반면, 좁은 트랜스포메이션은 그렇지 않다.

```scala
//좁은 종속성. rdd에 map 연산으로 (x, 1)의 튜플을 만든다.
val rdd2 = rdd1.map(x => (x,1))
//넓은 종속성, groupByKey
val rdd3 = rdd2.groupByKey()
```

## 성능에 대한 고려 사항

좁은 종석성은 파티션 간의 데이터의 이동을 요구하지 않는다. 그러므로 좁은 종속성은 드라이버와의 통신을 피요로 하지 않고, 임의의 숫자의 좁은 트랜스포메이션들은 드라이버가 보낸 명령어들을 몇 개의 레코드 집에서든(몇 개의 파티션에서든) 그 위에서 실행할 수 있다. 

- 좁은 트랜스포메이션들의 각 몸이 질의 실행 계획에서 하나의 "스테이지"안에서 연산할 수 있다고 말한다.
- 반면, 하나의 넓은 종속성과 엮인 셔플은 RDD의 평가에 새로운 스테이지로 표시된다. 테스크들은 하나의 파티션에서 계산해야 하고 넓은 종속성의 각 파티션에서 계산해야 하는 데이터들은 대부분 여러 머신에 나누어져 있기 때문에 넓은 종속성의 트랜스포메이션들은 파티션간의 데이터 이동이 필요하다. 그러므로 이후에 오는 연산들은 셔플이 완료되기 전에는 시작되지 않는다.

- 스테이지의 경계는 성능에 있어 중요한 고려 사항이다. join같은 다중 RDD 연산의 경우를 제외하면, 한 RDD와 연계된 스테이지들은 일렬로 실행되어야 한다. 그러므로 셔플은 데이터 이동과 잠재적인 디스크 입출력을(파일 셔플링을 위해) 요구하므로 비용이 비쌀뿐만 아니라 병렬 수행도 제한된다.



## 장애 내구성의 고려 사항

- 넓은 종속성에서 한 파티션의 실패는 재연산이 필요한 파티션 개수가 휠씬 많으므로 좁은 종속성의 파티션의 실패보다 더 많은 비용을 요구. 예를 들면 mappedRDD(map 연산의 결과 RDD 타입)의 부모 중 한 파티션이 실패했다면 자식들 중에서도 한 파티셔만이 재연산되어야 하는데, 이 재연산의 속도를 높이기 위해 해당 자식 파티션들의 태스크가 이그제큐터들에게 분산되어 실행된다.반면, 정렬된 RDD의 부모가 파티션을 잃게 된다면 (최악의 경우) 모든 자식 파티션을 재연산해야 할 수도 있다. 넓은 종속성의 트랜스포메이션들을 연속으로 놓고 실행하는 것은 그중 메모리 오류를 일으킬 확률이 높은 것들이 있다면 굉장히 높은 부하의 재연산을 불러올 수도 있는 위험성을 높이는 것이다. 특정 경우들에서는 RDD를 체크포인팅함으로써 중간 결과를 저장하는 것이 충분히 가치있을만큼 재연산의 비용이 높을 수 있다.



## coaleses는 특별함

coalescs연산은 RDD의 파티션 개수를 바꾸고자 할 때 사용한다. coalecse로 결과 파티션의 개수를 줄이면 자식 파티션들이 여러 부모 파티션들을 통합하게 되므로 각 부모 파티션은 정확히 하나의 자식 파티션을 위해서만 사용된다. 그러므로 파티션 개수가 변경되지만 좁은 트랜스포메이션이다.



# 내 트랜스포메이션은 어떤 타입의 RDD를 반환하는가?

- RDD란 2가지 측면에서 추상적인 개념
  - RDD는 거의 모든 타입의 (String, Row, Tuple) 레코드를 가질 수 있다.
  - RDD 인터페이스에 다양한 속성을 추가한 여러 구현체 중의 하나가 될 수 있다.

위 두 가지의 구분은 성능이나 평가 양쪽 측면에서 모두 중요하다.

첫 번째 구분은 일부 트랜스포메이션은 특정한 레코드 타입을 가지는 RDD에만 적용할 수 있기 때문에 중요하다.

두 번째 구분은 각 트랜스포메이션이 그런 RDD에만 적용할 수 있기 때문에 중요하며, 그로 인해 서로 다른 RDD 구현체에 동일한 트랜스포메이션이 호출되어도 다르게 평가될 수 있다. 특히 어떤 RDD구현체는 이전 트랜스포메이션으로부터 레코드 순서나 지역성 정보를 이어받아 갖고 있기도 하다.

RDD의 레코드 타입은 매우 중요하다. DataFrame을 RDD로 작업할 때 타입 정보를 잃어버리는 경우가 매우 흔다. DataFrame은 암묵적인 변환에 의해 Row의 RDD로 변환할 수 있다. 그러나 스파크 SQL의 Row객체는 강타입이 아니므로 스칼라 컴파일러는 Row 객체를 만들 위해 쓰인 값의 타입을 '기억'할 수 없다.

RDD로 변환하는 것은 DataFrame이 갖고 있던 스키마 정보를 날려 버리게 되므로 DataFrame의 스키마를 변수에 바인해 놓는 것이 중요하다. DataSet API의 장점 중 하나는 강타입이라는 것인데, 심징 RDD로변환한 뒤에도 타입이 유지된다.



# 객체 생성 최소화하기

'가비지 컬렉션은'은 더 이상 쓰이지 않는 객체 할당된 메모리를 정리하는 과정이다. 스파크는 JVM에서 실행되기 때문에 많은 자료구조들을 가지고 있기 떄문에 가비지 컬렉션은 스파크 작업에서 부담스러울 수밖에 없다.

그러므로, 우리는 객체의 크기나 숫자를 줄임으로써 GC에 대한 비용은 최소화할 수 있다. 즉 기존 객체를 재활용하고 메모리 공간을 덜 쓰는 자료 구조를 이용하여(기본 타입을 쓰는 등) 객체 크기나 개수를 줄일 수 있다는 말.



# 기존 객체 재활용하기.

아래 코드 참조

```scala
import org.apache.spark.rdd.RDD

class MetricsCalculator(
                         val totalWords: Int,
                         val longestWord: Int,
                         val happyMentions: Int,
                         val numberReportCards: Int) extends Serializable {
  def sequenceOp(reportCardContent: String): MetricsCalculator = {
    val words = reportCardContent.split(" ")
    val tW = words.length
    val lW = words.map(w => w.length).max
    val hM = words.count(w => w.toLowerCase.equals("happy"))

    new MetricsCalculator(
      tW + totalWords,
      Math.max(longestWord, lW),
      hM + happyMentions,
      numberReportCards + 1
    )
  }

  def compOp(other: MetricsCalculator): MetricsCalculator = {
    new MetricsCalculator(
      this.totalWords + other.totalWords,
      Math.max(this.longestWord, other.longestWord),
      this.happyMentions + other.happyMentions,
      this.numberReportCards + other.numberReportCards)
  }

  def toReportCardMetrics =
    ReportCardMetrics(
      longestWord,
      happyMentions,
      totalWords.toDouble / numberReportCards)
}

case class ReportCardMetrics(longestWord: Int, happyMentions: Int, averageWords: Double)
```



```scala
/*
주어지는 (판다 교사, 리포트 카드 문자열) 의 RDD는 교사별로 집계되고
단일 키별로(판단 교사, 리포트 카드 통계) 값의 RDD로 변환된다.
ReportCardMetrics라는 케이스 클래스가 가진 값이 통계값이 된다.

longestWord -> 교사가 쓴 모든 리포트 중 가장 긴 단어
happyMentions -> 해당 교사가 언급한 happy 개수
averageWords -> 해당 교사의 리포트 카드당 단어의 평균 개수
  */

//객체를 재사용하지 않는 경우.
def calculateReportCardStatistics(rdd: RDD[(String, String)]
                                 ): RDD[(String, ReportCardMetrics)] = {
  rdd.aggregateByKey(new MetricsCalculator(totalWords = 0,
    longestWord = 0, happyMentions = 0, numberReportCards = 0))(
    seqOp = ((reportCardMetrics, reportCardText) => reportCardMetrics.sequenceOp(reportCardText)),
    combOp = (x, y) => x.compOp(y))
    .mapValues(_.toReportCardMetrics)
}

```

```scala
//객체를 재사용할 경우
class MetricsCalculatorReuseObjects(
                                     val totalWords: Int,
                                     val longestWord: Int,
                                     val happyMentions: Int,
                                     val numberReportCards: Int) extends Serializable {

  def sequenceOp(reportCardContent: String): this.type = {
    val words = reportCardContent.split(" ")
    totalWords += words.length
    longestWord = Math.max(longestWord, words.map(w => w.length).max)
    happyMentions += words.count(w => w.toLowerCase.equals("happy"))
    numberReportCards += 1
    this
  }

  def compOp(other: MetricsCalculator): this.type = {
    totalWords += other.totalWords
    longestWord = Math.max(this.longestWord, other.longestWord)
    happyMentions += other.happyMentions
    numberReportCards += other.numberReportCards
    this
  }

  def toReportCardMetrics =
    ReportCardMetrics(
      longestWord,
      happyMentions,
      totalWords.toDouble / numberReportCards)
}
```



# 더 작은 자료 구조 사용하기.

스파크 작업을 시간과 공간 양쪽으로 최적화하는 중요한 수단은 사용자 정의 클래스가 아니라 기본 타입들을 쓰는 것. 이는 코드의 가독성을 떨어뜨릴 수는 있지만, 케이스 클래스나 튜플보다는 배열을 쓰는 것이 GC오버헤드를 줄이는 데 효과적이다.

 스칼라의 배열은 내부적으로도 자바 배열과 동일하며 스칼라 컬렉션 타입 중 메모리 효율이 가장 뛰어나다. 스칼라 튜플은 객체이므로 일부 경우에서는 비용이 큰 연산에 대해 튜플보다 두세 개까지 배열을 쓰는 것이 더 나을 수 있다.

스칼라 컬렉션타입들은들은 대게 배열보다 높은 GC오버헤드를 일으킨다.



# mapPartitions로 수행하는 반복자-반복자 트랜스포메이션

RDD의 mapPartition 함수는 레코드들의 반복자(iterator)를 받아 또 다른 반복자(결과 파티션을 나타냄)로 출력하는 함수를 인자로 받는다.

mapPartition는 문자열 파싱 같은 매우 간단한 데이터 변형에 사용할 수 있다. 물론 보조 정렬이나 고도로 특수한 경우의 집계 연산 같은 문제를 해결해 주는 복잡하고 큰 비용의 작업에도 적용할 수 있다.

mapPartitions 코드를 최적화하는 것은 복잡하면서도 뛰어난 성능의 스파크 코드를 만드는 데 중요한 부분을 차지한다.



이런 반복자-반복자 트랜스포메이션을 쓰는 주된 이점은 스파크가 선택적으로 데이터를 디스크에 쓸 수 있다는 것. 개념적으로 반복자-반복자 트랜스포메이션은 한 번에 하나씩 평가하는 절차를 정의하는 것을 의미한다. 그러므로 스파크는 전체 파티션을 메모리에 읽어 들이거나 모든 결과 레코드를 메모리의 컬렉션에 담아되돌려  줄 필요 없이 그런 절차를 레코드의 배치 처리로 적용할 수 있다. 

즉. 반복자-반복자 트랜스포메이션은 스파크가 하나의 이그제큐터에서 메모리에 담기에는 너무 큰 파티션들을 메모리 에러 없이 처리해준다. 그 뿐만 아니라 디스크 공간을 선택적으로 사용할 수 있다. 전체 파티션이 메모리 공간에 들어가기 곤란할 경우 반복자-반복자 트랜스포메이션은 파티션을 모두 디스크에 쓰지 않고 필요한 레코드만큼만 사용하여 디스크 I/O나 재연산에 들어가는 비용을 아낀다.







































































