# **Preview**

- 독보적인 장점  
  **=> 메모리 기반 처리와 함께 지연 평가 방식으로 효율을 극대화하는 능력**

- 스파크의 병렬 처리 모델
- 스파크 스케줄러
- 실행 엔진

- 스파크 <= 클러스터 매니저(얀, 메소스, 단독) <= 분산 저장 시스템(카산드라, S3, Hdfs) 의 **데이터 처리 생태계**를 가짐

## 스파크 컴포넌트

스파크는 데이터 처리를 위한 고수준의 질의 언어를 제공

**스파크 코어(spark core)** - 데이터 처리 프레임워크

스파크는 유연성 있는 분산 데이터세트(Resilient Distributed Dataset)라 불리는 데이터 추상화를 기반으로 만들어 짐.

- RDD란 지연 평가를 수행하며 정적인 타입을 가지는 분산 데이터 모음
- RDD에는 분산 데이터세트를 다룰 수 있도록 map, join, reduce 등 대략적으로 역할이 구분된 데이터 트랜스포메이션뿐만 아니라 저장 시스템과 스파크 JVM사이에서 데이터를 읽고 쓰는 I/O기능 또한 정의되어 있다.

### 스파크 SQL

- **스파크 SQL은 DataFrame이라고 불리는 반구조화의 데이터 타입을 위한 인터페이스를 정의**

- 스파크 SQL은 스파크 성능에 매우 중요한 컴포넌트이며, 스파크 코어만으로 할 수 있는 일도 많은 부분 스파크 SQL과 함께 적용해서 능을 극대화 시킬 수 있다.





## 스파크의 병렬 연산 모델:RDD

- 병렬 데이터 처리를 수행할 수 있는 클러스터 시스템 위에서 구동되는 드라이버(Driver) 혹은 마스터(master node)를 위한 프로그램을 사용자가 만들어야 함.
- 변경할 수 없는 형태의 분산된 객체들의모음 - **RDD**
- RDD를 구성하는 객체를 파티션(partition) 이라 하며, 경우에 따라 다르지만 저장된 노드가 아닌 다른 노드에서 계산 될수 있다.
- **스파크 클러스터 매니저** 는 스파크 애플리케이션에서 설정한 파라미터에 따라 분산 시스템에 이그제큐터들을 실행하고 분산해 주는 역할.
- **스파크 실행 엔진** 는 연산을 위해 이그제큐터들에게 데이터를 분산해 주고 실행을 요청



![](http://ww4.sinaimg.cn/large/006tNc79gy1g41vkobf91j30wt0u0npd.jpg)



- 스파크는 드라이버 프로그램이 RDD의 각 데이터들의 처리 단계를 결정하자마자 연산을 수행하는 것이 아니라 연산 시점을 뒤로 미루어 실제로 최종 RDD를 계산해야 하는 시점에 RDD 변형을 수행한다. 

- 스파크는 더 빠른 접근와 반복 연산을 위해 스파크 애플리케이션이 동작하는 동안 로드된 RDD를 이그제큐터 노드들의 메모리에 가지고 있을 수 있다. 이들은 스파크에서 변경 볼가능(immutable)하도록 구현되었기 때문에 데이터의 변경의 결과는 기존RDD가 아닌 새로운 RDD로 리턴.

## 지연 평가

- RDD의 연산은 완전히 게으른 방식을 채택
- 파티션은 액션이 호출되기 전까지는 계산되지 X
- 액션은 RDD가 아닌 다른 타입의 결과를 리턴하는 스파크 연산 종류의 하나로, 파티션 연산을 시작하게 하고 스파크 외의 시스템으로(이그제큐터 외부로) 결과를 보낼 수도 있다. ex)  데이터를 드라이버로 되돌려 주든지(count나 collect 같은 연산) 데이터를 외부 저장 시스템에 쓰는 것(copyToHadoop 등) 같은 일
- 액션은 스케줄러를 시작하게 하며 스케줄러는 RDD **트랜스포메이션**  간의 종속성에 바탕을 둔 지향성 비순환 그래프 (Directed Acyclic Graph) 를 생성
- 스파크는 최종 분산 데이터세트(각 파티션)의 각 객체를 생성하기 위해 취해야 할 일련의 각 단계를 정의하기 위해 역으로 거슬러 올라가는 방식으로 액션을 평가
- **실행 계획(execution plan)** 이란 부르는 이 각 단계의 순서에 따라 결과를 내놓을 떄까지 스케줄러는 각 단계마다 존재하지 않는 파티션을 계산해서 만들어 낸다.



#### 지연 평가의 성능과 사용성에서의 장점

지연 평가는 드라이버와 통신할 필요가 없는 연산들을 통합하여 데이터가 여러 단계를 거치지 않도록 한다. 예를 들어 스파크 프로그램이 동일 RDD에 map과 filter를 호출했다고 가정했을 때, 스파크는 최대한 각각의 함수 호출을 지연하여 액션함수가 들어올 때, 한 파티션에서 map, filter를 함꺼번에 수행하여 하나의 연산으로 수행되므로 연산 복잡성을 반으로 줄일 수 있다.



#### 지연 평가와 장애 내구성

스파크는 장애에도 강한다, 하드웨어나 네트워크 장애에도 작업이 완전히 실패하지 않고 데이터 유실이 일어나거나 잘못된 결과를 반환하지 않는다는 의미다. 스파크의 우수한 장애 내구성(fault-tolerance)구현 방식은 각 파티션이 자신을 재계산하는 데 필요한 중속성 정보 등의 데이터를 갖고 있기 때문에 가능한 것이다. 변경 가능한 객체를 사용자에게 제공하는 대부분의 분산 컴퓨팅 패러다임은 데이터 변경을 일일이 로깅해 놓거나 노드들에 데이터를 복제해 놓는 방식으로 장애를 대비.

반면, 스파크는 각 파티션이 복제에 필요한 모든 정보를 갖고 있으므로 각 RDD에서 데이터 변경 내역 로그를 유지하거나 실제 중간 단계들을 로깅할 필요가 없다. 만약 파티션이 유실되면 RDD는 재계산에 필요한 중속성 그래프에 대한 충분한 정보를 갖고 있으므로 더 빠른 복구를 위핸 병렬 연산을 수행할 수도 있다.



#### 지연 평가와 디버깅

지연 평가는 스파크 프로그램이 오직 액션을 수행한 시점에서만 문제가 발생하게 되므로 디버깅에 중요한 영향. 스파크 개발은 완전한 디버깅 정보에 접근할 수 있는 환경에서 개발하는 것이 가장 중요하다!



#### 메모리 영속화와 메모리 관리

맵리듀스와 비교해 스파크의 성능상 이점은 반복 연산이 들어 있는 사례에서 상당한 우위를 보인다. 이 성능 향상의 많은 부분은 스파크가 메모리 영속화(in-memory persistence)를 활용하는 덕택.

- 스파크는 데이터가 거치는 각 단계마다 디스크에 기록하는 대신 이그제큐터의 메모리에 데이터를 로드해 놓을 수도 있다. 그러므로 **파티션의 데이터에 접근이 필요할 때마다 메모리에서 꺼내 올 수 있다.**
- 스파크는 메모리 관리에 대한 3가지 옵션을 제공
  - 직렬화되지 않은 데이터를 메모리
  - 직렬화된 데이터를 메모리
  - 디스크



## 불변성과 RDD 인터페이스

**스파크는 RDD의 각 타입이 구현해야만 하는 속성들을 RDD인터페이스에 정의.**

- 이 속성들이란 실행 엔진이 RDD를 계산하는 데 필요한 데이터 위치에 대한 정보나 RDD의 종속성 같은 것들을 포함한 정보
- RDD는 정적인 타입인 데다 변경이 불가능하기 때문에 한 RDD에 대해 트랜스포메이션을 호출하는 것은 원래의 RDD를 수정하지 않고 새롭게 정의한 속성들을 가진 새로운 RDD를 리턴
- 3가지 방법으로 RDD 생성
  - (1) 기존 RDD에 트랜스포메이션 호출
  - (2) 스파크 API의 관문 역할을 하는 SparkContext 객체로부터 생성
  - (3)DataSet나 DataFrame을 변환(이것들은 SparkSession으로부터 만듬) / SparkContext는 스파크클러스와 실행 중인 스파크 애플리케이션 하나와의 연결을 나타낸다.

**스파크는 RDD를 표현하는 다섯가지 속성** 

- 기본적으로 요구되는 세 가지는 RDD를 구성하는 **파티션의 리스트**
- 각 파티션에 대한 반복 연산을 담당하는 **함수들**
- 다른 RDD들을 가리키는 **종속성 목록**

- 그 외, RDD는 선택적으로 **파티셔너**(스칼라 튜플로 표시되는 키/값 쌍을 레코드(row)로 가지는 RDD를 위함)
- **기본 위치 목록**(HDFS 파일의 위함) 등을 포함된다.



##### 이 다섯가지 속성은 다음의 다섯 가지 함수를 써서 확인해볼 수 있다.

- partitions()   
  : 분산 데이터세트의 부분들을 구성하는 파티션 객체들의 배열을 돌려준다. 파티셔너를 가진 RDD라면 각 파티션의 인덱스는 그 파티션의 데이터가 가진 각 키에 getPartition()을 호출했을 때의 결괏값과 같다.
- iterator(p, parenlters)  
  : 각각의 부모 파티션을 순회하는 반복자(iterator)가 주어지면 파티션 p의 구성요소들을 계산해 낸다. 이 함수는 RDD에서 각각의 파티션을 계산하기 위해 호출
- dependencies()  
  : 종속성 객체의 목록을 리턴
- partitioner()  
  : hashPartitioner같이 element와 partition 사이에 연관되는 함수를 갖고있는 RDD라면 스칼라의 Option타입으로 partitioner 객체를 리턴
- preferredLocations(p)  
  : 파티션 p의 데이터 지역성에대한 정보를 리턴

## RDD의 종류

스파크 스칼라 API의 구현은 추상 클래스, RDD를 포함하여 RDD는 다섯 가지 핵심 속성 뿐 **아니라 map과 collect같은 모든 RDD에서 사용가능한 트랜스포메이션과  액션**을 갖고 있다.



- 특별한 타입의 RDD에만 정의된 함수들은 몇몇 RDD 함수 모음 클래스에서 실제로 구현하고 있는데, PairRDDFunctions, OrderedRDDFunctions, GroupedRDDFunctions 같은 클래스



## RDD의 함수들 : 트랜스포메이션 vs 액션

- 액션은 부수효과를 포함하고 RDD가 아닌 것들을 리턴하는 데 비해 트랜스포메이션은 새로운 RDD를 리턴하는 함수.
- 액션은 정보를 드라이버에 되돌려 주거나 데이터를 안정된 저장 장치에 기록해 주기 때문에 스파크를 쓰는 프로그램은 반드시 액션을 사용해야 한다.
- 액션은 스파크에게 실제 연산을 실행하도록 강제하는 것
- persist를 호출하는 것도 마찬가지 역할을 하지만, 이는 스파크 잡이 끝나는 것으로 간주하지는 않는다.
- 데이터를 드라이버에 되돌려 주는 액션들로는 collect, count, collectAsMap, Sample, reduce, take
- 스파크 API의 파워는 대부분 트랜스포메이션에서 나옴.



## 넓은 종속성 vs 좁은 종속성

RDD가 어떻게 평가되는지 이해하기 위해서는 좁은 종속성의 트랜스포메이션과 넓은 종속성의 트랜스포메이션 두 가지 분류를 알아 두어야 한다.

- 좁으냐 넓으냐의 구분은 트랜스포메이션 결과 평가에 암암리에 중요한 영향을 끼치며, 당연하게도 성능에도 중요한 작용을 한다.



#### 좁은 종속성

자식 RDD의 각 파티션이 부모 RDD의 파티션들에 대해 단순하고 한정적인 종속성을 가지는 것으로,  
디자인 시점에 종속성을 결정할 수 있고, 부모 파티션과 상관이 없으며,  
각각의 부모가 최대 하나의 자식 파티션을 가진다면 이 종속성은 좁다고 할 수 있다.  
특히 좁은 트랜스포메이션의 파티션들은 하나의 부모 파티션에만 종속되거나(map 연산처럼)  
디자인 시점에 알게 된 부모 파티션들 중 알려진 일부에만 중속된다.(coalesce).  
그러므로 좁은 트랜스포메이션은 다른 파티션의 정보를 필요로 하지 않고 데이터의 임의의 부분에 대해 실행이 가능하다.

#### 넓은 종속성

임임의 데이터만으로 실행할 수는 없으며, 특별한 방법, 예를 들면 키의 값에 따라 파티셔닝된 데이터를 요구한다. 일례로 sort같은 경우 같은 범위의 키들이 같은 파티션 안에 존재하도록 레코드들을 파티셔닝해야 한다. 넓은 종속성의 트랜스포메이션은  sort, reduceByKey, groupByKey, join 그리고 rePartition 함수를 호출하는 모든 것을 아우름.



## 스파크 잡 스케줄링

 스파크 애플리케이션은 **고수준 스파크 로직이 작성되어 있는 드라이버 프로세스**와 **클러스터의 노드들**에 나뉘어 분포된 이그제큐터 프로세스들로 구성.

 스파크 프로그램 자체는, **드라이버 노드**에서 실행되며 일련의 명령들을 이그제큐터에 보내게 된다. 하나의 스파크 클러스터는 여러 개의 스파크 애플리케이션을 동시에 실행할 수 있다. 애플리케이션들은 클러스터 매니저에 의해 스케줄링되고 각각 하나의 SparkContext를 가진다. 그리고 스파크 애플리케이션들은 공존하는 여러 개의 잡을 차례로 실행하 수 있다. 잡들은 애플리케이션의 한 RDD가 호출하는 각 액션에 대응한다. 이 절에서는 스파크 애플리케이션이 스파크 잡(RDD 트랜스포메이션을 계산하는 프로세스)을 어떻게 실행하는지에 대해 살펴보자.



#### 애플리케이션 간의 자원 할당

스파크는 각 애플리케이션에 정적 할당과 동적 할당의 두 가지 방법의 자원 할당을 제공한다. 

정적 할당은 각 애플리케이션에 클러스터의 제한적인 자원을 최대한 할당하고 애플리케이션이 실행되는 동안(SparkContext가 실행 중인 한) 예약된다. 정적 할당의 범주 내에는 클러스터에 따라 다양한 종류의 자원 할당이 가능하다.

1.2버전부터 스파크는 정적 자원할당의 확장된 기능인 동적 자원 할당도 옵션으로 제공한다. 동적 할당에서는 이그제큐터가 스파크 애플리케이션의 필요에 따라 필요 자원량의 대략적인 예측치에 기초해 자원을 추가하거나 줄일 수 있다.



#### 스파크 애플리케이션

스파크 애플리케이션과 연계된 스파크 잡들은 드라이버 프로그램의 SparkContext에 정의되어 있다. SparkContext가 생기면 스파크 애플리케이션이 구동한다. SparkContext를 실행하면 드라이버와 이그제큐터들이 클러스터의 각 작업 노드에서 구동된다.

각 이그제큐터는 각자의 자바 가상 머신(JVM)을 가지며 한 노드에 여러 개의 이그제큐터가 존재할 수는 있지만 하나의 이그제큐터가 여러 노드에 걸쳐서 존재하는 않는다.

**SparkContext** 는 각 이그제큐터에 얼마나 많은 자원을 할당할 것인지를 결정하고, 스파크 잡이 실행될 때 각 이그제큐터는 RDD를 계산할 태스크 실행을 위한 슬롯을 가진다. 이를 통해 하나의 SparkContext는 스파크 잡 실행을 위한 설정 변수들의 한 집합으로 생각할 수 있다. 이 변수들은 SparkConf 객체를 통해 노출되는데, 이 객체로 SparkContext를 생성한다.



![](http://ww4.sinaimg.cn/large/006tNc79gy1g41vkobf91j30wt0u0npd.jpg)



우리가 SparkContext를 시작할 때 어떤 일이 생기는지를 보여 준다. 우선 드라이버 프로그램은 클러스터 매니저에게 신호를 보낸다.(Ping) 클러스터 매니저는 클러스터의 워커 노드들에(점선 동그라미로 표시) 다수의 이그제큐터를 띄운다(다이어그램에서 JVM은 사각형으로 표시했다.) 한 노드는 여러 개의 스파크 이그제큐터를 가질 수 있지만 하나의 이그제큐터가 여러 개의 노드로 확장되지는 않는다. 하나의 RDD는 파티션들이(실선 타원) 존재하는 이그제큐터들에 의해 평가될 것.

각 이그제큐터는 여러 개의 파티션을 가질 수 있지만 하나의 파티션을 여러 이그제큐터로 분산시킬 수는 없다.

#### 기본 스파크 스케쥴러

기본적으로 스파크는 선입선출방식으로 잡들을 스케쥴.

하지만 스파크는 라운드 로빈 방식으로 동시에 실행되는 잡들에 태스크를 할당하는, 즉 모든 잡이 끝날 때까지 각 잡에 태스크를 조금씩 분배해 주는 페어 스케줄러 방식도 제공.

페어 스케줄러는 잡들이 좀 더 공평하게 클러스터 자원을 공유하도록 해준다. 그러고 나서 스파크 애플리케이션은 SparkContext에서 해당 액션들이 호출된 순서대로 작업을 시작.



## 스파크 잡의 해부

 스파크의 지연 평가 패러다임에서 스파크 애플리케이션은 드라이버 프로그램이 액션을 호출하기 전까지는 '아무것도'하지 않았다. 각 액션마다 **스파크 스케줄러**는 실행 그래프를 만들고 **스파크 잡**을 시작한다. 각 잡은 최종 RDD를 만들어 내는 데 필요한 데이터 변환의 각 단계를 의미하는 **스테이지(stage)**들로 구성된다. 각 **스테이지**는 각 병렬 연산의 한 단위를 의미하며 이그제큐터들 위에서 실행되는 **다수의 태스크(task)**들로 구성된다.

*스케쥴러 - 스파크 잡 > 스테이지 > 태스크*



스파크 애플리케이션의 각종 컴포넌들의 트리 형태 구성과 이것들이 API과 어떻게 연계되는지 확인해보면,

**하나의 애플리케이션은 하나의 SparkContext/SparkSession 을 시작하는 것과 대응.**

각 애플리케이션은 하나의 RDD액션과 대응되는 잡을 여러 개를 가질 수 있다. 각 잡은 각각의 넓은 트랜스포메이션에 대응되는 스테이지를 여러 개를 가질 수 있다. 그리고 각 스테이지는 스테이지에서 수행되는 병렬 연산의 한 단위인 태스크 여러 개로 구성된다. 해당 스테이지의 결과 RDD에 있는 하나의 파티션마다 하나의 태스크가 존재한다.

![image-20190616115030564](http://ww2.sinaimg.cn/large/006tNc79gy1g42t2fnj6wj30zg0u0b2h.jpg)





#### DAG

스파크의 **고수준 스케줄링 레이어**는 각 스파크 잡의 스테이지의 지향성 비순환 그래프(Directed Acyclic Graph, DAG)를 만들기 위해 RDD 종속성 정보를 사용한다. 

스파크 API에서 이는 DAG스케쥴러로 불린다. 아마 이미 본 적이 있겠지만 **클러스터 접속, 설정 변수, 스파크 잡 시작과 관련된 에러들은 DAG 스케줄러 에러**로 나타난다. 이는 스파크 잡의 실행이 DAG에 의해 이루어지기 때문이다. DAG는 각 잡의 스테이지의 그래프를 만들고, 각 태스크가 실행될 위치를 결정하며, 클러스터에서 태스크 실행을 관리하는 TaskScheduler에게 정보들을 전달한다. TaskScheduler는 파티션들 간의 종속성 그래프를 만든다.

#### 잡(JOB)

잡은 스파크의 실행 구성에서 가장 높은 단계의 요소.

 **각 스파크 잡은 하나의 액션에 대응되며** 각 액션은 스파크 애플리케이션의 드라이버의 프로그램에서 호출.

액션을 개념적으로 구체화하는 한 가지 정의는 데이터를 스파크의 RDD 세상 바깥으로 갖다 놓는 그 무엇이라고 할 수 있다.(보통 데이터를 드라이버에 되돌려 주든지 어떤 안정적인 저장 시스템에 쓰는 경우가 될 것)

**스파크 실행 그래프의 간선(edge)들은 RDD 트랜스포메이션에서 파티션들 간의 종속성을 기반으로 한다.**

그러므로 RDD가 아닌 무언가를 되돌려 주는 연산은 더이상 자식을 가질 수 없다. 그래프 이론으로 말하면 액션은 DAG에서 leaf 노드 형태라고 말할 수 있을 것이다. 이렇게 수많은 트랜스포메이션의 한 집합은 하나의 실행 그래프로 구성할 수 있다. 하지만 스파크는 액션을 한 번 호출한 이후에는 더 이상 그래프에 추가를 할 수는 없다. 애플리케이션은 액션을 호출한 최종 RDD를 평가하기 위해 필요한 트랜스포메이션들을 포함한 잡을 바로 실행한다.

#### 스테이지(STAGE)

스파크가 트랜스포메이션의 지연을 평가하는 부분을 다시 떠올려보면, 트랜스포메이션들은 액션이 호출되기 전까지 실행되지 않는다. 이미 언급했듯이 하나의 잡은 하나의 액션을 호출하는 것으로 정의. 그리고 액션은 하나 이상의 트랜스포메이션을 가지며 **넓은 트랜스포메이션은 잡의 부분들을 스테이지로 정의.**



 각 스테이지는 스파크 프로그램에서 넓은 트랜스포메이션에 의해 생성되는 셔플 의존성에 대응한다. 높은 차원에서 보면 하나의 스테이지는 다른 이그제큐터나 드라이버와의 통신없이 하나의 이그제큐터에서 계산 가능한 태스크들의 집합으로 생각할 수 있다. 다시 말하면 하나의 새로운 스테이지는 언제든지 작업 노드들 사이에서 네트워크 통신이 요구될 때마다 시작된다.(ex, 셔플)



 이렇게 스테이지의 경계를 구분하는 종속성은 ShuffleDependencies로 불린다. 21페이지의 '넓은 종속성 vs 좁은 종속성' 에서 얘기했듯이 셔플은 sort나 gorupbyKey 같은 넓은 트랜스포메이션에 의해 발생하는데, 이는 데이터를 파티션들에 결쳐 재분배한다는 의미. 여러개의 좁은 종속성들은 하나의 스테이지로 묶을 수 있다.



예를 들면, flatMap, map, filter 단계가 모두 셔플을 요구하지 않기 때문에 하나의 스테이지로 연결할 수 있다. 그러므로 각 이그제큐터는 flatMap, map, filter 단계를 데이터의 접근 한 번으로 연달아 적용할 수 있다.



스테이지 경계에서는 **드라이버와의 통신을 요구하기 때문에 하나의 잡과 연계되는 스테이지들은** 병렬적으로 실행되기보다는 **순차적으로 실행**되어야 한다. 만약 join처럼 이후의 트랜스포메이션에서 연결이 되는 서로 다른 RDD들을 연산하는 경우라면 스테이지들은 병렬로 실행하는 것이 가능하다. 하지만 하나의 RDD를 연산하기 위한 넓은 트랜스포메이션들은 순차적으로 실행되어야만 한다. 그러므로 보통은 프로그램이 최소한의 셔플로 수행될 수 있게 설계하는 것이 바람직하다.



#### 테스크

하나의 스테이지는 여러 개의 Task로 이루어진다. 태스크는 실행 계층에서 가장 작은 단위이며 각각이 하나의 local 연산을 표현할 수 있다. 한 스테이지의 모든 태스크들은 서로 다른 데이터를 대상으로 동일한 코드를 실행한다. 한 태스크는 둘 이상의 이그제큐터에서 실행될 수 없다. 하지만 각 이그제큐터는 태스크 실행을 위해 동적으로 할당된 여러 개의 슬롯을 가지며, 이그제큐터가 떠 있는 동안 여러 태스크들을 슬롯만큼 동시실행할 수 있다. 스테이지당 태스크의 개수는 해당 스테이지의 결과 RDD의 파티션 개수에 대응된다.



```scala
def simpleSparkProgram(rdd: RDD[Double]): Long = {
  //stage1
  rdd.filter(_ < 1000.0)
  .map(x => (x, x))
  //stage2
  .groupByKey()
  .map{ case(value, groups) => (groups.sum,value)}
  //stage3
  .sortByKey()
  .count()
}
```

![image-20190616123131321](http://ww2.sinaimg.cn/large/006tNc79gy1g42u8za6xdj30u00u0b2h.jpg)



클러스터는 각 스테이지마다 필요한 모든 태스크를 동시에 실행할 수는 없다. 각 이그제큐터는 사용하는 코어의 개수가 정해져있는데, 이는 애플리케이션 레벨에서 설정되기는 하지만 대개는 클러스터의 물리적인 코어 개수와 대응된다. 스파크는 애플리케이션을 위해 할당된 이그제큐터 코어 개수의 총합보다 더 많은 태스크를 동시에 실행할 수는 없다.



즉, (이그제큐터 코어 개수의 총합 = 이그제큐터당 코어 개수 X 이그제큐터 개수)를 쓰면 SparkConf로부터 동시 실행 태스크의 개수를 구할 수 있다.

만약, 태스크 실행을 위한 슬롯보다 더 많은 파티션이 있다면, (즉 더많은 태스크) 추가적인 태스크들은 처음 실행된 태스크들이 끝난 다음 자원의 사용이 가능해질 때 이그제큐터에 할당될 수 있다.

대부분의 경우, 하나의 스테이지가 시작하기 전에 이전 스테이지의 모든 태스크가 완료되어야만 한다.

이런 태스크를 분산해주는 과정은 TaskScheduler가 담당하는데, 페어 스케줄러인지 FIFO스케줄러인지 ㄷ으에 따라 다르다.



어떤 면에서 스파크 실행 모델을 생각하는 가장 쉬운 방법은 스파크 잡은 하나의 최종 결과를 연산해 내는 데 필요한 RDD 트랜스포메이션들의 집합이라는 것이다. 

각 스테이지는 작업의 한 부분과 대응되며 스테이지는 드라이버의 도움없이 해당 부분을 완료할 수 있다.

다시 말하면, 하나의 스테이지는 파티션끼리 데이터가 전송되는 일 없이 연산이 가능한 단위다. 한 스테이지 내에서의 **태스크들은 데이터의 각 파티션에 대한 작업을 수행하는 단위들**이다.



































