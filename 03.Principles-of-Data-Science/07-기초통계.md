# Goal

- 데이터를 수집하고 표본 추출하는 방법
- 중심의 측정, 분산, 상대적 비교
- z-score를 사용해 데이터 정규화
- 경험적 법칙



좋다.

**그럼 통계란 무엇인가?**

통계는 어떤 포인트를 증명하거나 두렵게 만들어야 할 경우에 유용한데, 그 포인트는 무엇일까?

실험이나 모델의 전체 주제로서 모집단(population)을 정의할 수 있다. 근본적으로 모집단은 관심 있는 사람들이다. 누구에 대해서 이야기하려고 하는가? 

**모집단**  
: 예를 들어 모집단이 모든 직원(1000명 이상의 직원이 있다고 가정)이라면 그중에서 불법 약물의 사용 비율을 알고 싶다. 이 질문을 **모수(Parameter)**라고 한다.

모수는 모집단의 특성을 나타내는 수치적 측정치로 정의할 수 있다.

예를 들어 1,000명의 직원에게 모두 물어보고 100명이 약물을 사용 중이라면 약물 사용률 10%다. 여기에서 모수는 10%



그러나, 1,000명의 직원 모두에게 약물 사용 여부를 물을 수 없기 때문에, 가장 먼저 모집단의 표본(sample)을 취해야 한다. 약 200명에게 물어보고 그중 26명만이 약물을 사용하면 약물 사용률을 13%로 **모수의 추정치**

**즉, 통계가 이런 것이다.**



# 데이터를 얻고 표본 추출하는 방법?

**통계**가 모집단의 표본에 관한 것이라면 어떻게 표본을 취하는지 아는 것은 매우 중요하다. 데이터를 얻고 표본 추출하는 여러 가지 방법 중 몇 가지를 집중적으로 살펴보자.

## 데이터 얻기

데이터를 수집하는 두 가지 주요 방법은 **관측** 및 **실험**이다.

### 표본 추출 데이터

통계는 모집단의 표본을 측정한 결과라는 것을 기억!

측정하는 표본을 무엇으로 할지 결정하는 매우 일반적인 방법 두 가지

### 1. 확률 표본 추출

모집단에서 표본을 추출하는 방법으로, 모든 사람이 선택될 가능성이 있지만, 그 확률의 수는 사용자마다 다를 수 있다. 가장 간단 확률 표본 추출법은 무작위 표본 추출이다.

### 2.무작위 표본 추출



### 불균등 확률 표본 추출

한쪽으로 치우쳐지지 않도록 데이터를 샘플링하는 것을 말한다.

## 통계를 측정하는 방법

**중심 측정**

중심의 측정은 데이터셋의 가운데 또는 중심을 정의하는 방법. 

중심 측정값은 데이터셋의  '가운데' 값이다.

데이터셋의 **산술평균**은 모든 값을 합친 후 데이터 값의 수로 나눈 값.

```python
import numpy as np
np.mean([11,15,17,14]) == 14.25
```

이런 평균에서 갑자기 31 이라는 특이값(outliers)에 민간하기 때문에 평균에 큰 영향을 미침. 

```python
import numpy as np
np.mean([11,15,17,14,31]) == 17.6
```

또 다른 경우 가끔 중심의 더 나은 측정은 **중앙값(median)**이다.

데이터셋이 순서대로 정렬될 때 데이터셋의 가운데 있는 숫자

```python
import numpy as np
np.median([11,15,17,14]) == 14.5
np.median([11,15,17,14,31]) == 15
```

31이 영향을 덜 미치게 함.

많은 특이값이 있는 데이터셋으로 작업할 때 데이터셋의 중앙값을 사용하는 것이 더 유용할 수 있지만, 데이터에 많은 특이값이 없고 데이터 포인트가 거의 서로 가까운 경우 평균이 더 좋은 옵션일 수 있다.

그렇다면, 데이터가 확산됐는지는 어떻게 알 수 있을까?

#### 편차측정

중심의 측정은 데이터의 가운데를 정량화하는 데 사용되지만, 이제는 수집한 데이터가 어떻게 "퍼져 있는가"를 측정하는 방법을 모색할 것이다. 이것은 데이터가 많은 특이값을 내부에 숨겨 놓았는지 확인하는 데 유용한 방법.

```python
friends=[109,1017,1127,418,625,957,89,950,946,797,981 ....]
np.mean(friends) === 789.1
```

위 목록의 평균은 789이상이므로 평균 789명의 친구가 있다고 말할 수 있다.

그러나 특이값들이 있기 때문에 중앙값을 쓰는게 적절하지 않을까? 라고 생각할 수 있다.

```python
np.median(friends) == 769.5
```

이 값은 평균값에 상당히 가깝다. 좋은 생각이나 여전히 불편한 진실이 존재한다. 그래서 통계학자가 데이터의 편차를 측정하는 것이다. 편차의 가장 기본적인 척도인 범를 소개해보자. **범위**는 다음과 같이 단순히 최댓값에서 최솟값을 뺀 값이다.

```python
np.max(friends) - np.min(friends) == 1684
```

단순희 범위는 극단적인 두 값이 얼마나 멀리 떨어져 있는지 알려준다. 일반적으로 잘 쓰이지 않는다.

가장 일반적으로 쓰이는 편차 측정 방법인 **표준편차(Standard deviation)**

본질적으로 모집단 표본을 사용할 때 s로 표시하는 표준 편차는 데이터 값이 산술 평균에서 벗어나는 정도를 측정한다.

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fxonygpj35j309h05taa5.jpg)

파이썬에서는 `np.std(friends)`

(Cf, 분산은 단순히 표준 편차를 제곱한 것)

##### 변동 계수의 정의

**변동 계수(coefficient of variation)**는 데이터의 표준 편차와 평균의 비율을 정의하는 것

이 비율은(측정에서 나눗셈이 허용되고 의미가 있는 비율 수준에서 작업하는 경우에만 도움이 되는) 표준 편차를 표준화하는 방법이므로 데이터셋을 서로 비교하기 쉽다. 다른 척도로 존재하는 모집단에 퍼져있는 평균을 비교하려고 할 때 이 측정치를 자주 사용한다.

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fxoo90ryecj30x90i10ui.jpg)

##### 상대적 위치의 측정

척도를 만들기 위해 중심과 편차의 척도를 결합할 수 있다.

전체 데이터셋과 관련해서 특정 데이터 값이 위치하는 것을 측정하는 것이 **편차 측정값(measure of variation)**이다.

통계에서 매우 중요한 값인 **z-score**를 알아자.

**z-score**는 단일 데이터 값이 평균으로부터 얼마나 멀리 떨어져 있는지 알려주는 방법이다. x 데이터 값의 z-score는 다음과 같다.

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fxoodb1jo7j30zk0k0ad0.jpg)

- 분모는 표준편차

z-score가 특정 데이터 요소마다 개별화된 값이라는 것을 기억하자. z-score는 데이터 값에서 평균을 빼고 표준 편차로 나눠서 구할 수 있다. 이것은 매우 다른 척도로 존재하는 데이터를 표준화하고 데이터의 의미에 맞게 데이터를 정리하는 매우 효과적인 방법.

```python
z_scores= []
m = np.mean(friends)
s = np.std(friends)

for friend in friends :
    z = (friend - m) / s
    z_scores.append(z) # 도식화를 위해 점수 목록을 만듬
```

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fxooi7t8c6j30eq0cm0tl.jpg)

이 도표는 훨씬 더 낮고 높은 친구들이 있는 사람들을 평균적으로 골라내기 아주 쉽게 만든다. 예를 들어 인덱스 0의 개인은 평균적으로 친구가 적다.

그렇다. z-score는 데이터를 표준화하는 효과적인 방법이다. 즉, 전체 세트를 같은 척도에 놓을 수 있다. 예를 들어 각 사람의 일반적인 행복 척도를 측정해도 다음의 데이터셋과 비슷한 데이터셋을 갖게 된다.

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fxoor32gksj30v40ow43k.jpg)

- 열의 평균 찾기
- 열의 표준 편차 찾기
- 열의 각 요소에 z-score 함수 적용

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fxooycnwr5j30k00chwf5.jpg)



두 데이터셋 간의 상관관계는 두 데이터셋이 어떻게 움직이는지를 알려준다. 이것은 상관 계수(Correlation coefficients)라고 한다. 두 변수 간 연관성/관계의 강도를 설명하는 양적 측정이다.

상관관계에 대해 알아야 할 몇 가지 사항은 다음과 같다.

- -1과 1사이에 있다.
- 절대값이 클수록 변수 값의 관계가 강해진다.
- 가장 강한 상관관계는 -1,1 이다.
- 가장 약한 상관관계는 0이다.
- 양의 상관관계란 한 변수가 증가하면 다른 변수도 증가하는 경향이 있음을 의미
- 음의 상관관계란 한 변수가 증가할 때 다른 뱐수가 감소하는 경향이 있음을 의미한다.

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fxop6zibx8j30a304e0su.jpg)

- 행렬의 대각선은 양수로 채워진다. 이것은 변수와 그 자체 사이의 상관관계를 나타내기 때문이다. 물론 상관관계를 완벽하게 긍정적으로 만들어주는 완벽한 라인을 형성한다!
- 행렬은 대각선을 가로 질러 대칭이다. 이것은 Pandas에서 만들어진 모든 상관 행렬(correlation matrix)에 적용

상관 계수를 신뢰하는 데 있어 몇 가지 주의해야 할 점이 있다. 하나는 일반적으로 상관관계가 변수 간의 선형 관계를 측정하려고 시도한다는 것.즉, 측정에서 가시적인 상관관계가 없다고 해서 변수 간에 아무런 관계가 없음을 의미하지는 않는다. 단지 선을 쉽게 통과하는 최상의 선이 존재하지 않는다는 것을 의미한다.



정리하면, 상관관계를 사용해 변수 간의 관계에 대한 가설을 세울 수 있지만, 이러한 가정과 가설을 강화하기 위해 좀 더 정교한 통계 방법과 머신 러닝 알고리즘을 사용해야 한다.



## 경험적 법칙

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fxopdrlb81j30vj0bedi4.jpg)

경험적 법칙은 정규분포를 따를 것이라 가정하는 것을 말한다. 그러나 모든 데이터가 정상적으로 분포되는 것이 아니므로 경험적 법칙을 항상 사용 할 수 있는 것은 아니다. 어떤 종류의 분포를 분석하는 데 도움이 되는 또 다른 정리가 있다.