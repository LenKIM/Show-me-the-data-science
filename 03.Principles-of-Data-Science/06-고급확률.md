***확률은 발생할 수도 있고 발생하지 않을 수도 있는 이벤트를 모델링하는 수학.***



확률의 더 복잡한 원리와 에측 능력을 어떻게 사용할 수 있는지 살펴보자.

베이즈 정리(Bayes theorem) 및 확률 변수(random variablels)와 같은 주제는 나이브 베이지 알고리즘(Naive Bates algorithm)과 같은 일반적인 머신 러닝 알고리즘으로 이어진다.



이번 시간에는 다음과같은 것들을 살펴볼 예정입니다.

- 포괄적인 이벤트
- 베이즈 정리
- 기본 예측 법칙
- 확률 변수



시작하기 전에 **Collectively exhaustive events(포괄적인 이벤트)**를 살펴보자.

둘 이상의 이벤트 집합이 주어질 때 적어도 하나의 이벤트가 발생해야 하는 경우 이런 이벤트의 집합은 collectively exhustive(전체 포괄적)이라고 할 수 있다.

- 이벤트 집합(온도 < 60, 온도 > 90) 이 주어진다면 이들 이벤트는 전체적으로 포괄적이지 않다. 즉, 70과 10이 동시에 이루어질수 없으므로 **상호 포괄적**이다.
- 주사위 굴리기는 {1,2,3,4,5,6}의 이벤트 집합이 **전체 포괄적**. 이 이벤트집합이 유일하게 가능한 이벤트이기 때문에 적어도 하나는 발생해야 한다.

> 베이지안 아이디어 재검토

베이즈에 관한 이야기할 때 다음 세 가지와 서로 어떻게 상호작용하는지에 대해 이야기하게 된다.

- 사전 분포(Prior distribution)
- 사후 분포(Posterior distribution)
- 공산/가능성(likelihood)

기본적으로 사후를 찾는 데 관심이 있다.

베이지안 사고방식을 말하는 또 다른 방법은 데이터가 신뢰를 형성하고 업데이트한다는 것이다. 가설에 대한 생각으로 약간의 데이터가 주어지면 사전 확률을 얻거나 가설을 단순하게 생각한 다음 사후 확률을 얻는다.

#### 베이즈 정리

베이즈 정리는 베이지안 추론의 큰 결과다. 이것이 어떻게 형성되는지 살펴보면

- P(A) = 이벤트 A가 발생할 확률
- P(A | B) = 이벤트 B가 발생했을 때 이벤트 A가 발생할 확률
- P(A, B) = 이벤트 A와 B가 발생할 확률
- P(A, B) = P(A) * P(B|A) 

**베이즈 정리의 형태는 마지막 항목에서 나온 것!**

즉,

P(A, B) = P(A) * P(B|A)

P(B, A) = P(B) * P(A|B)

P(A, B) = P(B, A)

**P(A) * P(B|A) = P(B) * P(A|B)**

P(B)로 양변을 나누면 다음과 같이 베이즈 정리를 얻을 수 있다.

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fxd40y1anfj306t051mx6.jpg)

베이지 정리는 다음과 같이 생각할 수 있다.

- P(A|B)에서 P(B|A)를 얻는 방법이다.(단 하나만 있는 경우).
- P(A)를 이미 알고 있다면 (B를 알지 못하지만) P(A|B)를 얻는 방법이다.

가설과 데이터라는 용어를 사용해 베이즈에 대해 생각해보자. 

**'H = 주어진 데이터에 대한 가설이고, D = 주어진 데이터'라고 생각하자.**

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fxd43xymbwj30bv04djre.jpg)

####  *cf) 주어진 데이터를 감안할 때 가설이 정확할 확률*

P(H)는 데이터를 관찰하기 전의 가설 확률이며, **사전 확률 또는 사전이라고 한다.**

P(H/D)는 계산할 확률이며, 데이터를 관찰한 후의 **가설 확률이기 때문에 사후라고 한다.**

P(D/H)는 주어진 가설하에서 데이터의 확률이며, **공산이라고 한다.**

P(D)는 어떤 가설하에서 데이터의 확률이며, **정규화 상수**라고 한다.



사용 예

블로그 게시물을 자겅하는 두 명의 책임자 Lucy와 Avinash가 있다. 여러분은 과거의 Lucy의 게시물 중 80%, Avinash의 게시물 중 50%만 좋아했다. 아침에 새 블로그 게시물이 여러분의 책상에 올라왔지만 작성자는 언급되지 않았다. 아침에 새 블로그 게시물을 좋아했다. 이 게실물을 Avinash가 작성했을 확률은 얼마인가? 두 블로그는 매우 유사한 비율로 블로그 게시물을 작성한다.

- H = 가설 = Avinash가 작성한 블로그 게시물이다.
- D = 데이터 = 여러분은 그 블로그 게시물을 좋아한다

P(H|D) = 여러분이 게시물을 좋아하면 Avinash가 작성한 게시물일 확률

P(D|H) = Avinash가 작성한 게시물이면 여러분이 게시물을 좋아할 확률

P(H) = Avinash가 작성한 게시물일 확률

P(D) = 여러분이 게시물을 좋아할 확률

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fxd43xymbwj30bv04djre.jpg)

이제 공식을 적용시켜보자.

- P(H)는 주어진 블로그 포스트가 Avinash에서 나올 확률이다. 블로거가 비슷한 비율로 글을 쓸 때 양쪽 블로거로부터 50/50의 확률을 얻기 때문에 .5라고 가정할 수 있다.(이 경우 D를 이에 대한 데이터로 가정하지 않는다.)
- P(D|H)는 앞에서 말했듯이 Avinash의 게시물을 좋아할 확률이고 이것은 50%, 따라서 .5다.
- P(D)는 흥미롭다. 이것은 일반적으로 게시물을 좋아할 확률이다.
- 그들 중 적어도 한 명이 썼다.
- 그들 중 대부분이 썼다.
- 따라서 정확하게 그들 중 한 명이 썼다.



D = (From Avinash AND loved it) OR (From Lucy AND loved it)

P(D) = P(Loved AND from Avinash) OR P(Loved AND from Lucy)

P(D) = P(From Avinash) P (Loved|form Avinash) + P(from Lucy)|P(Loved | from Lucy)  
그 게시물을 좋아할 확률

P(D) = .5(.5) + .5(.8) = .65

**P(H|D) = .5 * .5 / .65 = .38**

이것은 이 게시물의 출처가 Avinash일 확률이 38%



#### 확률 변수

*실제 수치 값을 사용해 확률적 이벤트를 설명한다.* 



```python
h = 5
```

변수들은 한 번의 하나의 값으로 대응하며, 우연성에 종속된다.

확률 변수를 사용하면 확률 변수의 확률 분포를 구할 수 있다. 이 확률 분포는 변수의 가능한 값과 확률을 제공한다..

- X = 주사위 굴리기의 결과



사실상 확률 변수는 이벤트의 표본 공간(가능한 모든 결과 집합)에서 확률 값(0과 1사이)으로 값을 매핑하는 함수다. 이벤트는 다음과 같이 표현한다.

 f(event) = probability



#### 이산 확률 변수 (discreate random variables)

가능한 값의 셀 수 있는 수를 취한다. 예를 들어 주사위 굴리기 의 경우

모든 경우가 1/6이 나온다.

확률 변수에는 여러 속성이 있으며, 그중 두 가지는 기댓값(expected value)와 분산(variance)이다.

확률 질량 함수(PMF: Probability Maxx Function)를 사용해 이산 확률 변수를 설명할 것.

P(X = x) = PMF

이산 변수의 다음 예를 고려하면,

- 설문 조사 질문의 결과(예: 1-10점 척도)
- CEO가 1년 안에 사임할 것인지?(true 또는 false)

**확률 변수의 기댓값은 확률 변수의 오랜 반복된 표본 실행의 평균값**



```python
import random
```

```python
def random_variable_of_dice_roll():
    return random.randint(1,6)
```

```python
trials =[]
num_trials=100
for trial in range(num_trials):
    trials.append(random_variable_of_dice_roll())
    
print(sum(trials)/float(num_trials))
```

```
3.58
```



```python
num_trials = range(100, 10000, 10)
```

```python
avgs = []
```

```python
for num_trial in num_trials:
    trials = []
    for trial in range(1, num_trial):
        trials.append(random_variable_of_dice_roll())
    avgs.append(sum(trials)/ float(num_trial))
```

```python
import matplotlib.pyplot as plt
plt.plot(num_trials, avgs)
plt.xlabel('Number of Trials')
plt.ylabel("average")
plt.show()
```

![png](/Users/len/Downloads/Untitled1/output_6_0.png)

> Expected value = E[X] = ux = summation(Xi)(pi)



주사위 굴리는 3.5의 굴리기 값을 '기대할'수 있음을 보여준다.

확률 변수의 평균 기댓값은 변수 뒤에 있는 전체 아이디어를 파악하기에 일반적으로 충분하지 않다. 이러한 이유로 **분산**이라는 새로운 개념을 도입한다.

확률 변수의 분산은 변수의 확신을 나타낸다. 분산은 기대값의 가변성을 수량화한다.

**이산 확률 변수의 분산 공식은 다음과 같이 표현된다.**

> Variance = V[X] = a^2x = summation(Xi - ux)^2 pi



**분산**은 주고받는 측정 지표로 생각할 수 있다. 

예를 들어 100$ 와 80\$를 주고받는 추가 세부 사항을 명세서에 추가하면 이제는 다룰 수 있는 기대범위가 넓어진다.



*리커드 척도(likert scale)*

: **리커트 척도**(Likert scale)는 설문 조사 등에 사용되는 심리 검사 응답 척도의 하나로, 각종 조사에서 널리 사용되고 있다. 리커트 척도에서는 응답자가 제시된 문장에 대해 얼마나 동의하는지를 답변하도록 한다. 리커트 척도라는 명칭은 이 척도 사용에 대한 보고서를 발간한 [렌시스 리커트](https://ko.wikipedia.org/w/index.php?title=%EB%A0%8C%EC%8B%9C%EC%8A%A4_%EB%A6%AC%EC%BB%A4%ED%8A%B8&action=edit&redlink=1)(Rensis Likert)의 이름에서 따온 것이다(Likert, 1932). **라이커트 척도**라고도 한다.



*실제 적용해보기*

| Value       | X = 0 | X = 1 | X = 2 | X = 3 | X = 4 |
| ----------- | ----- | ----- | ----- | ----- | ----- |
| Probability | 0.02  | 0.07  | 0.25  | 0.4   | 0.26  |

기대값은? E[X] = 0(0.02) + 1(0.07) + 2(0.25) + 3(0.4) + 4(0.26) = **2.81**

분산값은? V[X] = $(0 - 2.81)^2$$(0.02)$  +  $(1 - 2.81)^2$$(7.02)$ +  $(2 - 2.81)^2$$(0.25)$ +  $(3 - 2.81)^2$$(0.4)$ + $(4 - 0.26)^2$$(0.26)$ = .93

이제 표준 편차와 프로젝트 점수의 기댓값을 모두 얻었으므로 결과를 요약하면, 프로젝트는 2.81 플러스 또는 마이너스 .96의 기대 점수를 가진다고 말할 수 있다.



**이산 확률 변수의 유형**

확률 변수의 특정 유형을 살펴봄으로써 실제로 확률 변수가 어떻게 작동하는지 더 잘 알 수 있다. 확률 변수의 이러한 특정 유형은 다양한 유형의 상황을 모델링하고 매우 복잡한 이벤트 모델링에 대해서 훨신 간단한 계산을 보여줌.



**이항 확률 변수**

단일 이벤트가 반복해서 발생하는 설정을 살펴보고 결과가 양성(positive)인 횟수를 계산.

<조건>

- 가능한 결과는 성공 또는 실패다.
- 실험의 결과는 다른 실험의 결과에 영향을 미치지 않는다.
- 실험 횟수가 설정됐다.(고정된 표본 크기)
- 각 실험의 성공 가능성은 항상 p다.

**이항 확률 변수**는 이산 확률 변수 X이며, 이항 설정에서 성공 횟수를 계산한다.  
모수는  n = 실험 횟수이고, p = 각 실험의 성공 확률이다.

$P(X = k)  =(n /k) P^K  (1-P)^n-^k$

여기서  $n/k$ = 이항 계수 = $n!$$/$$(n-k)!k!$



<예시>

도시에 있는 신규 레스토랑은 첫 해에 20%의 생존 기회를 자는다. 올해 14개의 레스토랑이 오픈하는 경우 일반에게 공개된 후 첫 해에 정확히 4개의 레스토랑이 생존할 확률을 확인해보자.

첫째, 이것이 2진법 설정임을 증명해야 한다.

- 가능한 결과는 성공이나 실패다(레스토랑이 생존하거나 생존하지 않거나)
- 실험의 결과는 다른 실험의 결과에 영향을 미치지 않는다.(한 식당의 개업이 다른 식당의 개업 및 생존에 영향을 주지 않는다고 가정)
- 실험 횟수가 설정됐다.(14개 레스토랑 오픈)
- 각 실험의 성공 가능성은 항상 p다(항상 20%라고 가정)

여기서 n = 14, p = .2라는 두 개의 모수

이 숫자를 이항 공식에 연결하면?

P(4) = (from14 to 4) .2^4 .8^10 = .17 즉 17%의 영업 기회를 가질 수 있다.

이항 확률 변수는 이항 설정에서 성공 횟수를 계산하는 이산 확률 변수다. 이것은 전환 가능성으로 웹사이트에 가입할 것 같은 사람 수를 세거나, 간단한 수준에서 하락 가능성으로 주가 움직임을 예측하는 것과 같이 다양한 데이터 중심 실험에 사용된다.



**기하 확률 변수**

실제로 하나의 이벤트가 반복해서 발생하는 설정을 볼 때는 이항 확률 변수와 매우 유사하다. 그러나 기하학적 설정의 경우 주요 차이점은 표본 크기를 고정하지 않는다는 점이다.

- 가능한 결과는 성공이나 실패다(레스토랑이 생존하거나 생존하지 않거나)
- 실험의 결과는 다른 실험의 결과에 영향을 미치지 않는다.(한 식당의 개업이 다른 식당의 개업 및 생존에 영향을 주지 않는다고 가정)
- **실험 횟수가 설정되지 않았다.(14개 레스토랑 오픈)**
- 각 실험의 성공 가능성은 항상 p다(항상 20%라고 가정)

다시, 예를 들어서 설명하면,

- 스타트업 기업이 첫 번째 투자를 얻기 위해 참여하는 VC미팅 수를 센다.
- 앞면을 얻기 위해 필요한 동전 던지는 수를 센다.

P(X = x) = (1 - p)[x - 1]p

이항 및 기하 설정 모두 성공이나 실패인 결과가 포함된다. 



**푸아송 확률 변수**

왜 이 확률 변수가 필요한지 이해하기 위해 모델화하려는 이벤트의 발생 확률이 적고 특정 시간대에 이벤트가 발생하는 횟수를 계산한다고 생각해보자. 과거 사례로부터 주어진 특정 기간 동안 평균 발생 횟수 u에 대한 아이디어가 있다면 

X = Poi(u)로 표시하는 푸아송 확률 변수는 일정 기간 동안 이벤트의 총 발생 횟수를 계산.

**즉, 푸아송 분포는 주어진 시간 간격에서 발생하는 이벤트의 수를 게산하는 이산 확률 분포**

- 사이트의 과거 실적을 기반으로 한 시간 동안 사이트에 일정 수의 방문자가 있을 확률을 찾는다.
- 과거 경찰 보고서를 기반으로 교차로에서 차량 충돌 횟수를 추정.

X= **주어진 간격에서 이벤트의 수**이고, 간격당 평균 이벤트 수를 a로 하면 주어진 간격에서 x이벤트를 관찰할 확률은 다음 수식으로 표시된다. 

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fxdazadnfej30iq041dg8.jpg)



**연속 확률 변수**

이산 확률 변수와 전적으로 달리 연속 확률 변수는 몇 가지 계산 가능한 값이 아닌 무한 수의 가능한 값을 취할 수 있다. 확률 질량 함수 대신 분포 밀도 곡선을 설명하는 함수를 호출

- 영업 담당자의 전화 통화 길이(통화 수가 아님)
- 20갤런(오일 드럼 수가 아님)으로 표시된 드럼의 실제 오일양

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fxdb2j3j8rj30rh082tc4.jpg)

 [참고](https://namu.wiki/w/확률%20변수)

